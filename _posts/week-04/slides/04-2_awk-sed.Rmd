---
title: "Week 4 - Unix Data Tools - I"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "default-fonts", "slides.css", "slides_copy.css"]
    lib_dir: libs
    nature:
      highlightStyle: rainbow
      highlightLines: true
      countIncrementalSlides: false
---
class:inverse middle center

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(eval = FALSE)
```

## *Week 4: Unix Data Tools*

----

# Part II: <br> awk and sed

<br> <br> <br> <br> <br>

### Jelmer Poelstra
### 2021/02/02 (updated: `r Sys.Date()`)

---

## `awk`

- `awk` is a small programming language in itself!  

- `awk` is great for *quick file processing*, especially on tabular data.

  It is not (necessarily) the best choice for complicated tasks &ndash;  
  perhaps best used as a very powerful tool rather than
  a stand-alone programming language.

<br>

To understand `awk`, we should cover its two core concepts:
  
  - **Record processing**
  
  - **Pattern-action pairs**

---

## `awk` record processing: Records and fields

- "Records":
  
  - `awk` processes *records* one at a time, like a `for` loop going line by line.  

  - By default, **each line is one _record_**.
  
  - The entire record is assigned to `$0`.

- "Fields":
  
  - Within a line, **each column is a _field_**.
  
  - Columns are automatically assigned to `$1`, `$2`, `$3`, etc. 

<br>

```sh
$ awk '{ print $0 }' my.txt           # $0: full line

$ awk '{ print $3 "\t" $2 }' my.txt   # $3 & $2: 3rd and 2nd column
```

---

## `awk` record processing: Pattern-action pairs

- **Pattern**: an expression or regex pattern &ndash; a *condition* to be tested.

- **Action**: If the pattern evaluates to true, the action is performed.

.content-box-blue[
General syntax: **`awk 'pattern { action }' file`**

Note also that the `awk` command is placed *between single quotes*.
]

--

<br>

- Only one of the two (action and pattern) is required:

  - Omit the pattern: action is performed for *every record*.
  ```sh
  $ awk '{ print $0 }' my.txt   # Pattern omitted
  ```
  
  - Omit the action: print all records that match the pattern.
  ```sh
  $ awk '$3 < 10' my.txt        # Action omitted
  ```
  
---

## Simple `awk` examples: action only

**First, we omit patterns, so all lines (records) are subjected
to the action:**

- If we then print the entire record with `print $0`,  
  we mimic `cat` &mdash; each line will be printed in its entirety.
  ```sh
  $ awk '{ print $0 }' example.bed
  ```

<br>

--

- We can also mimic `cut` &ndash; and here we go beyond `cut` to reorder columns:
  ```sh
  $ awk '{ print $3 "\t" $2 }' example.bed  # Cf. Buffalo example
  
  # What happes without "\t"?
  $ awk '{ print $3 $2 }' example.bed       # Columns concatenated
  $ awk '{ print $3,$2 }' example.bed       # Default sep: " "
  ```

---

## Simple `awk` examples: pattern (condition) only

**Now, we use patterns and omit the action: all matching lines are printed.**
  
- Print only lines where column 2 (start of BED feature) is larger than 30:
   ```sh
  $ awk '$2 > 30' example.bed
  ```
  
- Calculate the length of each BED feature (column 3 - column 2),  
  and only print lines in which the feature is at least 18 bp long:
  ```sh
  $ awk '$3 - $2 > 18' example.bed
  ```

--

- Print only lines from "chr1" &ndash; exact match for first column:
  ```sh
  $ awk '$1 == "chr1"' example.bed # Quote the string
  ```
  
- Regular expression patterns are placed between forward slashes:
  ```sh
  $ awk '$1 ~ /chr1/' example.bed # Looks for match in column 1
  $ awk '/chr1/' example.bed  # Looks for match anywhere on line
  ```

---

## `awk` comparison and logical operators

| Comparison  | Description
|-------------|-------------|
| `a == b`    | `a` is equal to `b`
| `a != b`    | `a` is not equal to `b`
| `a < b`     | `a` is less than `b`
| `a > b`     | `a` is greater than `b`
| `a <= b`    | `a` is less than or equal to `b`
| `a >= b`    | `a` is greater than or equal to `b`

---

## `awk` comparison and logical operators

| Comparison  | Description
|-------------|-------------|
| `a == b`    | `a` is equal to `b`
| `a != b`    | `a` is not equal to `b`
| `a < b`     | `a` is less than `b`
| `a > b`     | `a` is greater than `b`
| `a <= b`    | `a` is less than or equal to `b`
| `a >= b`    | `a` is greater than or equal to `b`
| `a ~ /b/`   | `a` matches regular expression pattern `b`
| `a !~ /b/`  | `a` does not match regular expression pattern `b`
| `a && b`    | logical and: `a` **and** `b`
| `a` <code>&#124;</code><code>&#124;</code> `b` | logical or: `a` **or** `b` *[note typo in Buffalo]*
| `!a`        | not a (logical negation)

---

## `r icon::fa("user-edit")` `awk` mini-practice

1. Use a pattern (condition) to only print features (= rows) in `example.bed`
   which end at position 28.

2. Use an action to print, for each row, the chromosome and the length of
   the feature (column 3 - column 2).

3. Combine the action from 1. with the pattern (condition) from 2.

---

## `r icon::fa("user-edit")` `awk` mini-practice: solutions

1. Use a pattern (condition) to only print features (= rows) in `example.bed`
   which end at position 28.
  ```sh
  $ awk '$3 == 28' example.bed
  ```

2. Use an action to print, for each row, the chromosome and the length of
   the feature (column 3 - column 2).
  ```sh
  $ awk '{ print $1, $3-$2 }' example.bed
  $ awk '{ print $1 "\t" $3-$2 }' example.bed # Alt: tab-delimited
  ```

3. Combine the action from 1. with the pattern (condition) from 2.
  ```sh
  $ awk '$3 == 28 { print $1, $3-$2 }' example.bed
  ```

---

## `awk`: Filtering and combining expressions

- Combining patterns &ndash; print *chr1* features longer than 10 bp:

  ```sh
  $ awk '$1 ~ /chr1/ && $3 - $2 > 10' example.bed
  ```

- Select *chr2* and *chr3* and add a column that contains feature length: 
  ```sh
  $ awk '$1 ~ /chr2|chr3/ { print $0 "\t" $3 - $2 }' example.bed
  ```

--

.content-box-info[
**'|'** can be used directly: `awk` uses *extended regex* (ERE).
]

.content-box-info[
We can use **`|`** *within* a regex,  
and **`||`** and **`&&`** to chain together multiple regex.

```sh
$ awk '/chr1|chr2/' example.bed

$ awk '/chr1/ || /chr2/' example.bed
```
]
  
---

## `awk` so far

> *So far, these exercises have illustrated two ways Awk can come in handy:*
> - *For filtering data using rules that can combine regular expressions and arithmetic*
> - *Reformatting the columns of data using arithmetic*

---

## `awk`: Actions before and after record processing

- The `BEGIN` and `END` patterns can be used to specify actions before and
  after record processing. Here:
  
    - We initialize a variable `s` before starting record processing;
    
    - For each record, add the sum of the feature length (col3 - col2) to `s`;
    
    - After record processing, calculate the mean by dividing by `NR`,  
      the number of records.
  
  ```sh
  $ awk 'BEGIN{ s = 0 };            
      { s += ($3-$2) };             
      END{ print "mean: " s/NR };' example.bed
  ```

--

.content-box-info[
The `+=` operator is shorthand for adding to a variable:
`x += 1` means `x = x + 1`. It is used in many languages including Python.
] 

.content-box-info[
When using multiple pattern-action pairs, separate them with "**`;`**".
]
---

## `awk` special variables and keywords

| keyword/<br>variable  | meaning    |
|----------|------------|
| `BEGIN`  | Used as a pattern that matches the start of the file
| `END`    | Used as a pattern that matches the end of the file
| `NR`     | Number of Records (running count; in `END`: total nr. of lines)
| `NF`     | Number of Fields (for each record)
| `$0`     | Contains entire record (usually a line)
| `$1` - `$n` | Contains one column each

---

## `awk` special variables and keywords

| keyword/<br>variable  | meaning    |
|----------|------------|
| `BEGIN`  | Used as a pattern that matches the start of the file
| `END`    | Used as a pattern that matches the end of the file [cf. `EOF`]
| `NR`     | Number of Records (running count; in `END`: total nr. of lines)
| `NF`     | Number of Fields (for each record)
| `$0`     | Contains entire record (usually a line)
| `$1` - `$n` | Contains one column each
| `FS`     | Input Field Separator (default: any whitespace)
| `OFS`    | Output Field Separator (default: single space)
| `RS`     | Input Record Separator (default: newline)
| `ORS`    | Output Record Separator (default: newline)

---

## `awk` functions

| Function         | Meaning                        |
|------------------|--------------------------------|
| `length(<string>)`        | Return number of characters
| `tolower(<string>)`       | Convert to lowercase
| `toupper(<string>)`       | Convert to uppercase
| `substr(<string>, <start>, <end>)`  | Return substring
| `split(<string>, <array>, <delimiter>)`   | Split into chunks in an array
| `sub(<from>, <to>, <string>)`        | Substitute (replace) regex
| `gsub(<from>, <to> <string>)`        | >1 substitution per line 
| print                     | Print, e.g. column: `print $1`
| exit                      | Break out of record-processing loop; e.g. to stop when match is found
| next                      | Don't process later fields: to next iteration
| 

---

## Counting columns with `awk`

- `NF` is the number of *fields*. This finally brings us to the
  column-counting example shown earlier in the Buffalo chapter:
  ```sh
  $ mus=Mus_musculus.GRCm38.75_chr1
  
  $ awk -F "\t" '{print NF; exit}' "$mus".bed
  ```
  
  .content-box-red[
  `r icon::fa("question")` &nbsp; Why do we need the `exit` function here?
  ]

<br>

--

- For the **GTF** file, we need to omit the header lines (starting with a `#`)
  before we can count columns, which we can with `grep` or `awk` itself:
  ```sh
  $ grep -v "^#" "$mus".gtf | awk -F "\t" '{print NF; exit}'
  
  $ awk -F "\t" '!/^#/ {print NF; exit}' "$mus".gtf
  ```

---

## Miscellaneous `awk`

- We can also use `NR` to print specific lines (here, 3-5):
  ```sh
  $ awk 'NR >= 3 && NR <= 5' example.bed
  ```

- We can convert a GTF file to a BED file (subtracting 1 from the end position):
  ```sh
  $ awk '!/^#/ { print $1 "\t" $4-1 "\t" $5 }' "$mus".gtf | \
        head -n 3
  ```

--

.content-box-info[
We'll skip the final example, which uses an "associative array"
(= "dictionary" in Python) and a `for` loop within `awk` &ndash;
this level of complexity is where switching to Python/R often makes sense.  
But have a look if you like `awk`!
]

.content-box-info[
If you work a lot with sequencing data, check out the `bioawk` section.
]

---

## Replacing strings with `sed`

- `sed` is most often used to perform string replacements,  
  using the syntax `'s/pattern/replacement/[modifiers]'`,  
  where `s` stands for **substitute**.
  
  For instance, we can replace "chrom" by "chr" like so:

  ```sh
  $ head -n 3 chroms.txt # before sed
  #> chrom1  3214482 3216968
  #> ...
  
  $ sed 's/chrom/chr/' chroms.txt | head -n 3
  #> chr1  3214482 3216968
  #> ...
  ```

--

<br>

- For **global substitution** (>1 per line), we use the **`g`** modifier,  
  and for **case-insensitive** matching, the **`i`** modifier:
  
  ```sh
  $ sed 's/chrom/chr/ig' chroms.txt | head -n 3
  ```

---

## `sed` output options

- Note that `sed` does not edit the file in place, and outputs to standard out.
  Usually, we redirect the output to a new file:
  ```sh
  $ sed 's/chrom/chr/ig' chroms.txt > chroms_renamed.txt
  ```

- When we want replacements in place, **don't redirect to the same file!**
  
  ```sh
  $ sed 's/chrom/chr/ig' chroms.txt > chroms.txt # NO!!
  ```
  
  .content-box-red[
  `r icon::fa("question")` &nbsp; Why does this fail?
  ]

--

- But we can instruct `sed` to perform the replacement **in place** like so:

  ```sh
  $ cp chroms.txt chroms_inplace.txt
  $ sed -i 's/chrom/chr/' chroms_inplace.txt # Edits file!
  
  # Or create a backup copy using "inplace=<backup-suffix>"
  $ cp chroms.txt chroms_inplace2.txt
  $ sed --inplace=backup 's/chrom/chr/' chroms_inplace2.txt
  ```

---

## Reformatting using `sed`

- Let's say we want to replace the format `chr1:28427874-28425431`
  ("chrom:start-end") by having a tab (`"\t"`) between each field.  
  
  We would normally do this using input from a file,  
  but we can nicely try things out with input piped from `echo`:
  ```sh
  # Use two consecutive sed calls:
  $ echo "chr1:28427874-28425431" | sed 's/:/\t/' | sed 's/-/\t/'
  
  # Use -e for multiple expressions:
  $ echo "chr1:28427874-28425431" | sed -e 's/:/\t/' -e 's/-/\t/'
  
  # Use a character class to match both the : and - at once:
  $ echo "chr1:28427874-28425431" | sed 's/[:-]/\t/g'
  ```

--

.content-box-info[
Note that `tr` would also work for this task:
```sh
$ echo "chr1:28427874-28425431" | tr ':-' '\t'
```
]

---

## `r icon::fa("user-edit")` `sed` mini-practice

In `Mus_musculus.GRCm38.75_chr1_genes.txt`:

1. The geneIDs were for the wrong organism: replace `ENSMUS` by `GALGAL`.
   (Don't write to a new file, but check your result by piping into `head`.)
   
2. Replace the tabs by an underscore.
   (Don't write to a new file, but check your result by piping into `head`.)
   
3. Do both at the same time, and write to a new file `genes_fixed.txt`.

---


## Backreferences in regular expressions

Let's say our start and end columns are reversed.
In `awk`, fields-as-variables (`$1`, etc.) makes reordering easy.
How can we do this with `sed`?

- We can use **backreferences**, which allow you to capture a matched string,
  and *recall it*.
  (A general regex feature: we will see this in Python.)

- Backreferences are *captured* in parentheses:  **`(pattern1)-(pattern2)`**,
  and *recalled* using **`\1`** for the first one
  **`\2`** for the second one, etc.

--

- For instance, in `sed`, to invert the order of two words:

  ```sh
  $ echo "inverted words" | sed -E 's/(\w+) (\w+)/\2 \1/'
  # words inverted
  ```

- Recalling a backreference can also happen while matching!

  ```sh
  echo "abab" | grep -E '(ab)\1'
  # abab
  ```

--

  .content-box-info[
  For `grep` & `sed`, don't forget to turn on extended regex with **`-E`**!
  ]

---

## Reformatting using `sed` (cont.)

- So, let's invert these two fields:
  ```sh
  $ echo "28425431-28427874" | sed -E 's/([0-9]+)-([0-9]+)/\2-\1/'
  #> 28427874-28425431
  ```
  
- Going back to the format that has `chr` as well:  
  ```sh
  $ echo "chr1:28425431-28427874" | \
      sed -E 's/(chr[0-9]+):([0-9]+)-([0-9]+)/\1:\3-\2/'
  #> 28427874-28425431
  ```

- What if *some* chromosomes had names like `chr9a`?  
  To allow for any character up until the delimiter (**`:`**),  
  we could use **`:`** as a character class and *negate* it:
  ```sh
  $ echo "chr9a:28425431-28427874" | \
      sed -E 's/(chr[^:]+):([0-9]+)-([0-9]+)/\1:\3-\2/'
  #> 28427874-28425431
  ```

---

## Reformatting using `sed` (cont.)

- Finally, we can reformat the output. Here is the example from Buffalo,
  which gives tab-separated (**`\t`**) output:
  
  ```sh
  $ echo "chr1:28427874-28425431" | \
      sed -E 's/^(chr[^:]+):([0-9]+)-([0-9]+)/\1\t\2\t\3/'
  ```
  
  <br>
  
  .content-box-info[
  Note the caret sign **`^`** in **`s/^`**,
  which matches the beginning of a line.
  
  Not to be confused with a **`^`** as the first character inside **`[]`**,
  which is used for negation (!).
  
  The counterpart of **`^`** is **`$`**,
  which matches the end of a line.
  ]

---

## Print only matching or selected lines using `sed`

- Let's say we want to **extract a list of transcript IDs** from a GTF file,  
  which are formatted as `"transcript_id "ENSMUST00000160944"`.

  ```sh
  $ grep -v "^#" "$mus".gtf | head -n 3 | \
        sed -E 's/.*transcript_id "([^"]+)".*/\1/'
  ```
  
--
  
  .content-box-q[
  What went wrong?
  ]
  
--
  
  .content-box-answer[
  By default, non-matching lines are also printed &ndash;  
  and for those lines, there was no replacement to be made,  
  and they were printed in full.
  ]
  
---

## Print only matching or selected lines using `sed`

- We can tell `sed` to only print matching lines using the **`-n`** option,
  which turns off printing lines, and then using the **`p`** modifier for matches,
  to print those lines:
  ```sh
  # Print only lines containing the pattern 'abc' (mimics grep!): 
  $ sed -n '/abc/p' 
  ```

- So let's apply this technique to our GTF file:
  ```sh
  $ grep -v "^#" "$mus".gtf | head -n 3 | \
        sed -E -n 's/.*transcript_id "([^"]+)".*/\1/p'
  ```

<br>

- We can also use this construct to simply print specific line numbers:
  ```sh
  $ sed -n '20,50p' "$mus".gtf # Print lines 20-50
  ```

---

## Misc. `sed`

- Note that you can use **other delimiters than `/`** in the substitution command,
  which can be useful when patterns and/or replacement contain slashes:
  
  ```sh
  $ echo "data/fastq/sampleA.fastq" | sed 's#data/fastq/##'
  #> sampleA.fastq
  ```

<br>

.content-box-info[
Almost any character works, but the "rarer" the character, the better.  
]

---

## McIlroy's oneliner

```sh
$ cat file | tr -c A-Za-z '\n' | \
    tr A-Z a-z | \
    sort | \
    uniq -c | \
    sort -rn | \
    sed 10q
```

---
class: inverse middle center

# Questions?

----

<br> <br> <br> <br>

---
class: inverse middle center

# Bonus Materials

----

<br> <br> <br> <br>

---
background-color: #f2f5eb

---

## Subshells

```sh
$ (zgrep "^#" "$mus".gtf.gz; \
    zgrep -v "^#" "$mus".gtf.gz | sort -k1,1 -k4,4n) | \
    gzip > "$mus"_sorted.gtf.gz
```

---

## A subshell and a custom function

- "Subshell" between ( ): both head and tail get the same standard input:
  
  ```sh
  (head -n 2; tail -n 2) < file
  ```

- Creating a custom function:

  ```sh
  # Note that there was an error in Buffalo's function, lacking a trailing ";"
  i() { (head -n 2; tail -n 2) < "$1" | column -t; }
  ```
  
  - This is a nice trick, but ...
  
  - Mention aliases?

---

## Process substitution

```sh
$ cat <(echo "hello, process substitution")
```

```sh
$ cat $(echo "hello, process substitution")
#> cat: hello,: No such file or directory
#> cat: process: No such file or directory
#> cat: substitution: No such file or directory
```

```sh
$ echo "hello, process substitution" | cat
```

---

## Process substitution (cont.)

- Capturing input streams:
  ```sh
  program --in1 <(makein raw1.txt) --in2 <(makein raw2.txt) \
  --out1 out1.txt --out2 out2.txt
  ```

- Capturing output streams:
  ```sh
  program --in1 in1.txt --in2 in2.txt \
  --out1 >(gzip > out1.txt.gz) --out2 >(gzip > out2.txt.gz)
  ```

- Combining both:
  ```sh
  program --in1 <(makein raw1.txt) --in2 <(makein raw2.txt) \
      --out1 >(gzip > out1.txt.gz) --out2 >(gzip > out2.txt.gz)
  ```

- Why is this useful? Why not write intermediate files?

---
background-color: #f2f5eb

## Greedy and non-greedy matching with regex

- When matching with regular expressions,
  you need to take care to match to "greedily".
  
  For instance, when using a delimiter to try to define the end of the match,
  but this delimited occurs multiple times, problems can occur:
  
  ```sh
  $ echo 'transcript_id "ENSMUST00000160944"; gene_name "Gm16088"' \
        > greedy_example.txt
  
  $ sed -E 's/transcript_id "(.*)".*/\1/' greedy_example.txt
  # ENSMUST00000160944"; gene_name "Gm16088
  ```
  
- Instead, ...

  ```sh
  $ sed -E 's/transcript_id "([^"]+)".*/\1/' greedy_example.txt
  # ENSMUST00000160944
  ```

---
background-color: #f2f5eb

## Optional install for Mac users: <br> `GNU` instead of `BDS` tools

Assumes you have already installed Homebrew &mdash;
if not, go back to the optional installation instructions in Week 1.

```sh
brew install coreutils # Basic tools like ls, cat, head, tail etc.
brew install grep      # To get GNU grep, not included in basic tools
brew install gnu-sed   # To get GNU sed, also not included in basic
```

- After this, use `gcat` instead of `cat`, `ggrep` instead of `grep` etc.

- To check your installation, e.g.:
  ```sh
  ggrep --version
  ```

---

## Optional instal: bioawk

```sh
git clone git://github.com/lh3/bioawk.git && cd bioawk && make && mv awk bioawk && sudo cp bioawk /usr/local/bin/
```
