<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 13 - Reproducible workflows with Snakemake</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30}) })</script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/mark.js/mark.min.js"></script>
    <link href="libs/xaringanExtra-search/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":true,"autoSearch":true}) })</script>
    <link rel="stylesheet" href="slides.css" type="text/css" />
    <link rel="stylesheet" href="slides_copy.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class:inverse middle center





# *Week 13 &amp;ndash; &lt;br&gt; Reproducible workflows with Snakemake*

----

# II: Getting started with Snakemake

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

### Jelmer Poelstra
### 2021/04/08 (updated: 2021-04-07)

---
class:inverse middle center

# Overview

----

.left[
- #### [Snakemake basics and our first Snakefile](#basics)
- #### [Using input/output directives &amp;ndash; and relationships between rules](#io)
- #### [Using a "rule all"](#rule-all)
- #### [Using *{input}* and *{output}* placeholders](#io-curly)
- #### [Using wildcards to generalize rules](#wildcards)
- #### [Specifying samples/input files with *glob_wildcards()*](#glob)
- #### [Rules that aggregate across samples](#aggregate)
- #### [Modifying an input file](#modify-input)
]

---

## Setup

We will be running a dummy Snakemake workflow.

First, let's open a terminal and load your `ipy-env` Conda environment,
which should have Snakemake installed:

```sh
module load python/3.6-conda5.2
source activate ipy-env

snakemake --help          # Should print lots to screen
```

&lt;br&gt;

Let's create a directory for our workflow:

```sh
mkdir /fs/ess/PAS1855/users/$USER/week13/zoom_workflow
cd /fs/ess/PAS1855/users/$USER/week13/zoom_workflow
```

---

## Setup: create dirs and files

Next, we'll create some necessary directories and files, such as:

- `data` will contain dummy FASTQ files for three samples:
  `smpA`, `smpC`, `smpG`.

- `res` is where we will put our results.

- `workflow` will contain the "Snakefile" and a dir for "DAGs"
  (Directed Acyclic Graphs, in our case workflow diagrams).

```sh
mkdir -p data scripts res workflow/DAGs

touch workflow/Snakefile

echo "AAAAAAA" &gt; data/smpA.fastq
echo "CCCCCCC" &gt; data/smpC.fastq
echo "GGGGGGG" &gt; data/smpG.fastq
```

---

## Setup: create dummy scripts

Finally, we'll create three one-line dummy scripts just for the sake of allowing
us to test building a workflow and see if we are implementing it correctly:

- `trim.sh` &amp;ndash; A "FASTQ trimming script" that will just report the
  name of the file passed to it, and print its contents.
  
- `map.sh` &amp;ndash; A very similar "mapping script".  
  (To keep things very simple for now, it just takes a FASTQ file and no reference
  genome file to which the FASTQ file should be mapped.)

- `count.sh` &amp;ndash; A script that will take multiple "BAM" files, report
  their names, and print their contents to screen.

&lt;br&gt;

```sh
echo 'echo "FASTQ $1 after trimming" &amp;&amp; cat $1' &gt; scripts/trim.sh

echo 'echo "BAM from FASTQ $1 :" &amp;&amp; cat $1' &gt; scripts/map.sh

echo 'echo "Counts for $# BAM files:" &amp;&amp; cat $@' &gt; scripts/count.sh

chmod u+x scripts/*     # Make the scripts executable
```

---

## Setup: check our dir structure

Let's take a look at our directory contents with `tree`:

```sh
tree
#&gt; ├── data
#&gt; │   ├── smpA.fastq
#&gt; │   ├── smpC.fastq
#&gt; │   └── smpG.fastq
#&gt; ├── res
#&gt; ├── scripts
#&gt; │   ├── count.sh
#&gt; │   ├── map.sh
#&gt; │   └── trim.sh
#&gt; └── workflow
#&gt;     ├── DAGs
#&gt;     └── Snakefile
#&gt;
#&gt; 5 directories, 7 files
```

---

## Snakemake

- Although it's a general workflow management tool,
  it was written by a bioinformatician.
  In practice, it appears to be used mostly for sequence data workflows.

- Cross-platform and compatible with all HPC schedulers.  
  Works on laptop, clusters, and cloud without modification to the main workflow!
  
- Uses Python &amp;ndash; and is named after it.

--

- Also named after, and based on, Make: a utility that runs so-called
  Makefiles in which you specify a set of tasks to be executed.
  
  You may have used make to install software from source  
  (the `./configure &amp;&amp; make &amp;&amp; make install` sequence),  
  as software installation instructions are often specified in Makefiles.

---
name: basics
class: inverse middle center

# Snakemake basics and our first Snakefile

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Snakemake basics

- **Snakemake workflow instructions are written in a file that is usually called
  `Snakefile`** (no extension).
  
  This file is typically placed in the project's root dir or in a `workflow` dir.

--

&lt;br&gt;

- To actually run the Snakemake workflow that is specified in your `Snakefile`,
  you call `snakemake` in the shell from your project's root dir:

  ```python
  # Our Snakefile will be automatically detected if it is called:
  # `[Ss]nakefile` or `workflow/[Ss]nakefile`
  $ snakemake -j1
  
  # If necessary, we can call the Snakefile by name with "-s":
  $ snakemake -j1 -s my_other_snakefile.smk
  ```

  .content-box-info[
  With recent Snakemake versions, we *always* need to specify the `-j` option,
  which is the maximum number of jobs (processes) that you want Snakemake
  to run in parallel. 
  ]
  
---

## Snakefile basics

- **Snakefiles are basically Python scripts with some special Snakemake syntax.**
  (You can therefore include any arbitrary Python code in a Snakefile!)

- Snakefiles primarily consist of **rules**.
  Each rule describes a *component of the workflow*, like a script to be run.

--

- Rules are defined using the `rule` keyword:

  ```python
  rule my_rule:
        # ...Things to do in rule my_rule...
       
  rule another_rule:
        # ...Things to do in rule another_rule...
  ```

  .content-box-info[
  Note that this syntax is similar to that of defining a Python function,
  including the indentation on the next lines.  
    
  Instead of `def my_func(args):`, we use `rule my_rule:`
  ]
  
---

## Snakefile rules

**Most rules describe an action that should be performed, like**:

- A script that should be run.
- A shell command calling some external program.
- Stand-alone shell (or Python) code.

```python
rule fastqc:
    shell: "scripts/run_fastqc.sh data/sampleA.fastq.gz"
          
rule multiqc:
    shell: "multiqc results/fastqc_dir"
```

--

```python
rule count_words:
    shell: "scripts/cnt_words.py data/bookA.txt &gt; res/bookA_cnt.txt"
          
rule capitalize:
    shell: "cat res/bookA_cnt.txt | tr a-z A-Z &gt; res/bookA_ucnt.txt"
```

.content-box-info[
These examples all use a shell command for different purposes  
(**`shell` directive**), but others are possible, e.g. **`run`** for Python code.
]

---

## Snakefile version 1

Let's add the following to the empty `workflow/Snakefile`:

```python
rule trim:
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

.content-box-q[
What does our "workflow" do &amp;ndash;or pretend to do&amp;ndash; so far?
]

--

.content-box-answer[
We first trim and then map a FASTQ file for a single sample.
]

---

## Running Snakemake for the first time

When we call `snakemake`, we can **specify the rule we want to run**  
(here, we also use the **`-p` option** to print the shell commands being run):
  
```sh
$ snakemake -j1 -p trim
#&gt; Building DAG of jobs...
#&gt; Using shell: /bin/bash
#&gt; Provided cores: 1 (use --cores to define parallelism)
#&gt; Rules claiming more threads will be scaled down.
#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       trim
#&gt;         1
#&gt; Select jobs to execute...
#&gt; 
#&gt; [Wed Mar 31 07:40:50 2021]
#&gt; rule trim:
#&gt;     jobid: 0
#&gt; 
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; [Wed Mar 31 07:40:50 2021]
#&gt; Finished job 0.
#&gt; 1 of 1 steps (100%) done
#&gt; Complete log: [...]/.snakemake/log/2021-03-31T074049.781992.snakemake.log
```

---

## Thursday setup

```sh
module load python/3.6-conda5.2
source activate ipy-env

snakemake --help          # Should print lots to screen
```

&lt;br&gt;

```sh
$ cd /fs/ess/PAS1855/users/$USER/week13/zoom_workflow

# The res dir should contain the following file after our first run
# If not, go back in the slides and run Snakemake
$ ls res
#&gt; res/smpA_trim.fastq
```

---

## Running Snakemake for the first time (cont.)

Let's look at the output file:

```sh
$ cat res/smpA_trim.fastq
#&gt; FASTQ data/smpA.fastq after trimming
#&gt; AAAAAAA
```

Now we **run the second rule**, `map`:
  
```sh
$ snakemake -j1 -pq map
#&gt; Job counts:
#&gt;        count   jobs
#&gt;        1       map
#&gt;        1
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
$ cat res/smpA.bam
#&gt; BAM from FASTQ res/smpA_trim.fastq :
#&gt; FASTQ data/smpA.fastq after trimming
#&gt; AAAAAAA
```

.content-box-info[
The `-q` (`--quiet`) option keeps Snakemake's output minimal.
]

---
class: inverse middle center
name: io

# Using input/output directives &lt;br&gt; and relationships between rules

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Try running the second rule from scratch

What if we remove the output files and try running second rule:


```sh
$ rm res/*

$ snakemake -j1 map
#&gt; [...] 
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
*#&gt; cat: res/smpA_trim.fastq: No such file or directory
#&gt; [Wed Mar 31 08:51:45 2021]
#&gt; Error in rule map:
#&gt;     jobid: 0
#&gt;     shell:
#&gt;         scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
#&gt;         (one of the commands exited with non-zero exit code; note that snakemake uses bash strict #&gt; mode!)
#&gt; 
#&gt; Shutting down, this might take some time.
#&gt; Exiting because a job execution failed. Look above for error message
```

That didn't work &amp;ndash; Snakemake did not figure out it could create the missing
file `res/smpA_trim.fastq` by first running the `trim` rule.

---

## Indicating relationships between rules

For Snakemake to properly run your pipeline and start to have some added value,
we would like it to:

- Understand the **relationships (*dependencies*) between different rules**,
  such as the order in which they should be run.
  
- Be able to check for the presence of appropriate output files.

- Remove output files that were produced by jobs (processes) that produced an
  error, like our mapping step above.
  
  ```sh
  # Now we do have output from a job that produced an error!
  $ ls res
  #&gt; smpA.bam
  
  $ rm res/smpA.bam
  ```

---

## Indicating relationships between rules (cont.)

**These things are handled by `input` and `output` directives for each rule.**
For example:


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```
  
---

## Indicating relationships between rules (cont.)

**These things are handled by `input` and `output` directives for each rule.**
For example:


```python
rule trim:
    input: "data/smpA.fastq"
*   output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
*   input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

**Because the output of `rule trim` is the input of `rule map`**,  
Snakemake will be able to tell that:
  
- `rule map` should be run before `rule trim`.
  
- `rule trim` should only be run if the output from `rule map` is *actually present*.

---

## Indicating relationships between rules (cont.)

Therefore:

- **Relationships/dependencies between rules are _implicit_**:  
  they are inferred from the `input` and `output` directives.
  
- The order of the rules as written in the Snakefile is largely irrelevant
  (except that the first rule will be run by default).

---

## Snakefile version 2: with input/output directives


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---

## Running Snakemake again

- Earlier, we saw that we can specify a *rule* as an argument when running
  Snakemake. But we can also specify any rule's **output file(s)** as defined
  in the `output` directive.

- Let's try that:

  ```python
  $ snakemake -j1 -pr res/smpA_trim.fastq
  #&gt; [...]
  #&gt; rule trim:
  #&gt;   input: data/smpA.fastq
  #&gt;   output: res/smpA_trim.fastq
  #&gt;   jobid: 0
  #&gt;   reason: Missing output files: res/smpA_trim.fastq
  #&gt; 
  #&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
  #&gt; [...]
  ```

  .content-box-info[
  The **`-r` (long form: `--reason`) option** makes Snakemake tell us
  why it decides to run each job.
  ]
  
---

## Snakemake will figure out what needs to be run

Here is one of the things that makes Snakemake powerful &amp;ndash;  
when we run a command like:

```python
$ snakemake -j1 &lt;file_to_produce&gt;
```

- It will figure out **which *additional* rules need to be run** in order to run
  the requested rule (/ produce the requested file) successfully.

- When doing so, it doesn't just check if files are missing but also
  **whether any output files are older than input files**,
  which will also trigger a run.

--

- Similarly, Snakemake **won't run** if the output file is already present *and*
  is more recent than the input file&lt;sup&gt;[1]&lt;/sup&gt;.
  
- (Snakemake will also create any necessary output directories.)

.footnote[
&lt;sup&gt;[1]&lt;/sup&gt; Though you can always force a run, even if output files are present,  
&amp;nbsp; &amp;nbsp; &amp;nbsp; with the `--forcerun` option.
]

---

## Asking for the final output file

So, let's ask for Snakemake to produce **the final of our two output files**.  
(Recall that we also tried this before we had indicated relationships between
rules with `input` and `output`, and it failed.)
 
```sh
$ rm res/*  # First we remove the old output

$ snakemake -j1 -pr res/smpA.bam
#&gt; [...]  
#&gt; rule trim:
#&gt;     input: data/smpA.fastq
#&gt;     output: res/smpA_trim.fastq
#&gt;     jobid: 1
#&gt;     reason: Missing output files: res/smpA_trim.fastq
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; [...]    
#&gt; rule map:
#&gt;     input: res/smpA_trim.fastq
#&gt;     output: res/smpA.bam
#&gt;     jobid: 0
#&gt;     reason: Missing output files: res/smpA.bam; Input files updated by another job: #&gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
#&gt; [...]  
```
  
---

## Visualizing the workflow with a "DAG"

To better understand the relationships between rules that Snakemake infers,
we can visualize the "*Directed Acyclic Graph*" (**DAG**) for the workflow:

```sh
$ snakemake --dag res/smpA.bam | \
      dot -T svg &gt; workflow/DAGs/v2.svg 
```

- `snakemake --dag` will compute the DAG.
- We pipe that into the Graphviz `dot` command.
- We save `dot`'s output in SVG (Scalable Vector Graphics) format.

--

.pull-left[
&lt;p align="center"&gt;
&lt;img src=img/v2.svg width=40%&gt;
&lt;/p&gt;
]

.pull-right[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
*Still extremely simple, but we'll work on that!*
]

---

## What will Snakemake run?

First off, if we don't specify any rule or output file in our Snakemake call,  
the **first rule** will be run.

.content-box-q[
For the Snakefile below, which we've seen before:

If we don't specify a rule, will anything other than the first rule be run?
]


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---

## What will Snakemake run?

.content-box-answer[
With no arguments, the first rule (`rule trim`) will be run.  
`rule map` will not because `rule trim` does not depend on it.
]


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---
name: rule-all
class: inverse middle center

# Using a "rule all"

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Using a "rule all"

Because Snakemake executes the first rule by default,
it is handy to **define a "pseudorule" as the first rule** which will
trigger the execution of the full workflow.

Such a rule has only `input`, and no `output` or `action`,
and is usually called `rule all`.

.content-box-q[
Can you think of what kind of files we would specify as `input` in `rule all`?
]

--

.content-box-answer[
Typically, the `input` of `rule all` consists of all final output files
of the workflow.
  
Though more specifically, it has all files that are
**not used as input for another rule (i.e., "endpoints")** &amp;ndash;
some of these files may in fact be produced early on in the pipeline,
such as MultiQC output.
]

---

## Snakefile version 3: with rule all

.content-box-q[
What should be the `input` for `rule all` for our Snakefile below?
]


```python
rule all:
    input: 

rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---

## Snakefile version 3: with rule all (cont.)

.content-box-answer[
The output of the final rule of the workflow: `res/smpA.bam`.
]


```python
rule all:
    input: "res/smpA.bam"

rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---
name: snakefile_3

## Running the workflow again

```sh
$ snakemake -j1 -pq
#&gt; Job counts:
#&gt;        count   jobs
#&gt;        1       all
#&gt;        1       map
#&gt;        1       trim
#&gt;        3
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
```

---
name: io-curly
class: inverse middle center

# Using {input} and {output} placeholders

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Using {input} and {output} placeholders

Because we have to specify input and output files both in the
`input` / `output` directives *and* in the actual commands,
we are currently repeating ourselves:


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

---

## Using {input} and {output} placeholders (cont.)

We can prevent this by using `{input}` and `{output}` placeholders:


```python
rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

---

## Using {input} and {output} placeholders (cont.)

We can also **name individuals inputs and outputs**,  
which is useful in case we have more than one:


```python
rule map:
    input:
        fastq="data/smpA.fastq",    # NOTE THE COMMA
        ref="data/genome.fa"
    output: "res/smpA_trim.fastq"
    shell: "scripts/map.sh -r {input.ref} {input.fastq} &gt; {output}"
```

.content-box-info[
Different `input` files are **separated by a comma**:
- When a directive has multiple entries (e.g. `input`), a comma is required.
- When there is only one, a trailing comma is still accepted.
]

---

## Snakefile version 4: &lt;br&gt; with {input} and {output} placeholders


```python
rule all:
    input: "res/smpA.bam"

rule trim:
    input: "data/smpA.fastq"
    output: "res/smpA_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/smpA_trim.fastq"
    output: "res/smpA.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

---
class: inverse middle center
name: wildcards

# Using wildcards to generalize rules

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Generalizing a rule to run for any input file

**What if we want to run `trim` for multiple files?**

Do we create a rule for each file? Do we need to use a script that loops,
or do we create a loop in the Snakefile?

&lt;br&gt;

--

This is where Snakemake gets particularly powerful, but also more complicated:
we can include **wildcards** in our rule to take care of this.

---

## Introducing wildcards

To define **wildcards**, we again use curly braces `{}` &amp;ndash;  
but note that we never explicitly define what `{smp}` should hold!


```python
rule trim:
    input: "data/{smp}.fastq"
    output: "res/{smp}_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
```

--


```python
$ snakemake -j1 res/smpA_trim.fastq
```

If we then run the command above, Snakemake will:

1. Realize it can produce the requested output file
   `res/smpA_trim.fastq` by replacing the `{smp}` wildcard in `res/{smp}_trim.fastq` 
   with `smpA`. 

2. Knowing that the wildcard value is `smpA`,
   Snakemake will next look for input file `data/{smp}.fastq`, i.e. `data/smpA.fastq`.  
   
   Since this input file exists, it will go ahead and run rule `trim`
   with that input file.

---

## Snakefile version 5: &lt;br&gt; with wildcards in all applicable rules

Next, we can use an equivalent wildcard in our other rule, so our Snakefile
becomes:


```python
rule all:
    input: "res/smpA.bam"

rule trim:
    input: "data/{smp}.fastq"
    output: "res/{smp}_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/{smp}_trim.fastq"
    output: "res/{smp}.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

---

## Running the workflow again

Now, if we run:

```sh
$ rm res/*

$ snakemake -j1 -pq res/smpA.bam
#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       map
#&gt;         1       trim
#&gt;         2
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
```

Snakemake will figure out it first needs to run `rule trim` with wildcard
value `smpA`,
and then `rule map` with the same wildcard value.

--

&lt;br&gt;

.content-box-warning[
Note that wildcards operate entirely within a single rule and not across rules!
]

---

## Using wildcards to generalize our rule

OK, very nice &amp;ndash; but we still haven't run the same rule multiple times for
different input files! We have three files in total:

```sh
data/smpA.fastq data/smpC.fastq data/smpG.fastq
```

.content-box-q[
What would happen if we just ran Snakemake with a rule name?

```sh
$ snakemake -j1 map
```
]

--

.content-box-answer[
You may expect Snakemake is able to detect these input files,
and infer it can use `smpA` / `smpC` / `smpG` as the wildcard values, but:

```sh
$ rm res/*
$ snakemake -j1 map
#&gt; WorkflowError:
#&gt; Target rules may not contain wildcards. Please specify concrete files or a rule without wildcards.
```
]

---

## Using wildcards to generalize our rule

So, **Snakemake complains that there is no "concrete" rule.**

Snakemake does not peek at possible input files to infer wildcards --
it works the other way around and first determines what the **output files**
should be --
but in this case, it has no concrete instructions for output files to produce.

**So, we will need to tell Snakemake about the different samples that
can be used as the wildcards.**

---

## Using wildcards to generalize our rule (cont.)

The simplest way to specify our input samples is by listing them at the top of
the Snakefile. **Recall that we can just use Python code!**


```python
SAMPLES=["smpA", "smpC", "smpG"] 

rule all:
    input: ...
    
rule trim:
    input: "data/{smp}.fastq"
    output: "res/{smp}_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/{smp}_trim.fastq"
    output: "res/{smp}.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

**Now how do we modify `rule all`'s `input` accordingly?**

---

## Using wildcards to generalize our rule (cont.)

We want `rule all`'s `input` to be a list of the three output files that
our final rule (`map`) can produce for each sample:

```sh
"data/smpA.fastq"   =&gt;  'res/smpA.bam'
"data/smpC.fastq"   =&gt;  'res/smpC.bam'
"data/smpG.fastq"   =&gt;  'res/smpG.bam'
```

--

We can use a *list comprehension* to create this list:


```python
SAMPLES=["smpA", "smpC", "sampC"]

rule all:
    input: [ "res/" + sample + ".bam" for sample in SAMPLES]
```

--

But Snakemake also provides a few convenience functions &amp;ndash;  
and **`expand()`** comes in useful in such cases:


```python
input: expand("res/{smp}.bam", sample=SAMPLES)
```

---

## Snakemake's expand() function

While in the example above, the list comprehension was nearly as concise as
`expand()`, the latter is particularly convenient when dealing with multiple
lists, and you want all possible combinations among these lists:

```python
SAMPLES = ["sampleA", "sampleB", "sampleC"]
READS = ["R1", "R2"]

expand("{sample}_{read}.fastq.gz", sample=SAMPLES, read=READS)
#&gt; ['sampleA_R1.fastq.gz', 'sampleA_R2.fastq.gz',
#&gt;  'sampleB_R1.fastq.gz', 'sampleB_R2.fastq.gz',
#&gt;  'sampleC_R1.fastq.gz', 'sampleC_R2.fastq.gz']
```

--

.content-box-info[
You can try out how `expand()` works in an IPython window:

```python
from snakemake.io import expand, glob_wildcards

SAMPLES=["smpA", "smpC", "smpG"] 
expand("res/{smp}.bam", smp=SAMPLES)
#&gt; ['res/smpA.bam', 'res/smpC.bam', 'res/smpG.bam']
```
]

---

## Snakefile version 6: &lt;br&gt; with wildcards and the expand() function


```python
SAMPLES=["smpA", "smpC", "smpG"] 

rule all:
    input: expand("res/{smp}.bam", smp=SAMPLES)
    
rule trim:
    input: "data/{smp}.fastq"
    output: "res/{smp}_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/{smp}_trim.fastq"
    output: "res/{smp}.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

.content-box-info[
Note that our list at the top now specifies sample IDs
*that are part* of the input file names: with those,
we can identify the full input file names **via** the output file names.
]

---

## Visualizing and running the workflow again

```sh
$ snakemake --dag | dot -T svg &gt; workflow/DAGs/v6.svg 
```

&lt;br&gt;

&lt;p align="center"&gt;
&lt;img src=img/v5.svg width=70%&gt;
&lt;/p&gt;

---

## Visualizing and running the workflow again

```sh
$ snakemake -j1 -pq

#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       all
#&gt;         3       map
#&gt;         3       trim
#&gt;         7
#&gt; scripts/trim.sh data/smpC.fastq &gt; res/smpC_trim.fastq
#&gt; scripts/map.sh res/smpC_trim.fastq &gt; res/smpC.bam
#&gt; scripts/trim.sh data/smpG.fastq &gt; res/smpG_trim.fastq
#&gt; scripts/map.sh res/smpG_trim.fastq &gt; res/smpG.bam
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
```

---
class: inverse middle center
name: glob

# Specifying samples/input files &lt;br&gt; with glob_wildcards()

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Alternative options to specify (sample) IDs

It's not necessarily all that convenient to have to manually list sample IDs
at the top of the Snakefile &amp;ndash; in practice, we may have many!

There are a couple of alternatives, but we will use **globbing** to determine
which input files are present, and infer the sample IDs from the input file names.

Snakemake has another convenience function for this: **`glob_wildcards()`**.

&lt;br&gt;

--

.content-box-info[

Other options include:

- Snakemake accepts **config files** &amp;ndash;
  we can list the samples there and access the list from within the Snakefile.
  That's certainly no more convenient,
  but it's good not to have the IDs hardcoded in the Snakefile.

- We can read in a **metadata file** with the list of IDs,
  or even a tabular file that we read with `pd.read_csv()` &amp;ndash;
  this can also be done in the Snakefile!
]

---

## Snakemake's glob_wildcards() function

With `glob_wildcards`, we can extract parts of file names as follows:

```python
SAMPLES = glob_wildcards("data/{smp}.fastq").smp
```

Note the `.smp` at the end:
we extract the list that was stored in `smp` because we named our wildcard `smp`.

--

&lt;br&gt;

.content-box-info[
Again, you could  also try that in an IPython window:

```python
import os
uname = os.environ.get('USER')
os.chdir('/fs/ess/PAS1855/users/' + uname + '/week13/zoom_workflow')

glob_wildcards("data/{smp}.fastq").smp
#&gt; ['smpC', 'smpG', 'smpA']
```
]

---

## Snakefile version 7: with glob_wildcards()


```python
SAMPLES = glob_wildcards("data/{smp}.fastq").smp

rule all:
    input: expand("res/{smp}.bam", smp=SAMPLES)
    
rule trim:
    input: "data/{smp}.fastq"
    output: "res/{smp}_trim.fastq"
    shell: "scripts/trim.sh {input} &gt; {output}"
          
rule map:
    input: "res/{smp}_trim.fastq"
    output: "res/{smp}.bam"
    shell: "scripts/map.sh {input} &gt; {output}"
```

---

## Running the workflow again

```sh
rm res/*

snakemake -j1 -pq

#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       all
#&gt;         3       map
#&gt;         3       trim
#&gt;         7
#&gt; scripts/trim.sh data/smpC.fastq &gt; res/smpC_trim.fastq
#&gt; scripts/map.sh res/smpC_trim.fastq &gt; res/smpC.bam
#&gt; scripts/trim.sh data/smpG.fastq &gt; res/smpG_trim.fastq
#&gt; scripts/map.sh res/smpG_trim.fastq &gt; res/smpG.bam
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
```

---
class: inverse middle center
name: aggregate

# Rules that aggregate across samples

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## An aggregation rule

In the current `trim` and `map` rules,
we use `{smp}` wildcards to **run the rule multiple times, one for each sample.**

In other words, Snakemake is basically looping over the different values for
`{smp}` (`smpA`, `smpC`, `smpG`), processing one per iteration.

--

&lt;br&gt;

What if we needed to **include all samples in a single command**? 

For example, our next step will be to create a gene count matrix that
includes all samples, as is customary in RNAseq analysis.

---

## An aggregation rule (cont.)

The solution is simply to provide a **list of files to `input`** &amp;ndash;  
and we will again use the `expand()` function to do so:

```python
rule count:
    input: expand("res/{smp}_trim.fastq", smp=SAMPLES)
    output: "res/count_table.txt"
    shell: "scripts/count.sh {input} &gt; {output}"
```

Note also that:

- Our `output` directive no longer contains a wildcard.

- In our shell command, we continue to use the `{input}` and `{output}`
  pointers in the same way as for the file-by-file rule.

---

## An aggregation rule (cont.)

```python
rule count:
    input: expand("res/{smp}_trim.fastq", smp=SAMPLES)
    output: "res/count_table.txt"
    shell: "scripts/count.sh {input} &gt; {output}"
```

&lt;br&gt;

.content-box-q[
What other change do we need to make in our Snakefile?
]

--

.content-box-answer[
Change `rule all` to list the output of the now-final rule:

```python
rule all:
    input: "res/count_table.txt"
    #expand("res/{smp}.bam", smp=SAMPLES)
```
]

---

## Snakefile version 8: with an aggregation rule

```python
SAMPLES = glob_wildcards("data/{smp}.fastq").smp

rule all:
    input: "res/count_table.txt",

rule trim:
    input: "data/{smp}.fastq",
    output: "res/{smp}_trim.fastq",
    shell: "scripts/trim.sh {input} &gt; {output}"

rule map:
    input: "res/{smp}_trim.fastq",
    output: "res/{smp}.bam",
    shell: "scripts/map.sh {input} &gt; {output}"

rule count:
    input: expand("res/{smp}.bam", smp=SAMPLES),
    output: "res/count_table.txt",
    shell: "scripts/count.sh {input} &gt; {output}"
```

---

## Visualizing and running the workflow again

```sh
$ rm res/*

$ snakemake --dag | dot -T svg &gt; workflow/DAGs/v8a.svg 
```

&lt;p align="center"&gt;
&lt;img src=img/v7.svg width=55%&gt;
&lt;/p&gt;

---

## Visualizing and running the workflow again

```sh
$ snakemake -j1 -pq

#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       all
#&gt;         1       count
#&gt;         3       map
#&gt;         3       trim
#&gt;         8
#&gt; scripts/trim.sh data/smpG.fastq &gt; res/smpG_trim.fastq
#&gt; scripts/map.sh res/smpG_trim.fastq &gt; res/smpG.bam
#&gt; scripts/trim.sh data/smpC.fastq &gt; res/smpC_trim.fastq
#&gt; scripts/trim.sh data/smpA.fastq &gt; res/smpA_trim.fastq
#&gt; scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam
#&gt; scripts/map.sh res/smpC_trim.fastq &gt; res/smpC.bam
#&gt; scripts/count.sh res/smpG.bam res/smpC.bam res/smpA.bam &gt; res/count_table.txt
```

---

## Visualizing and running the workflow again

Now that we have run the entire workflow, note that all boxes have dashed lines:

```sh
$ snakemake --dag | dot -T svg &gt; workflow/DAGs/v8b.svg 
```

&lt;p align="center"&gt;
&lt;img src=img/v7b.svg width=55%&gt;
&lt;/p&gt;

---
class: inverse middle center
name: modify-input

# Modifying an input file

----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Modifying an input file

**What if we modify one of the input files?**  
(Recall that the `touch` command, when passed an existing file,
will just update the "last-modified" date and do nothing else.)

```sh
$ touch data/smpA.fastq

$ snakemake --dag | dot -T svg &gt; workflow/DAGs/v8c.svg 
```

--

.pull-left[
&lt;p align="center"&gt;
&lt;img src=img/v7c.svg width=88%&gt;
&lt;/p&gt;
]

.pull-right[
Look at that!

Snakemake realizes it needs to rerun the trimming and mapping steps
for `smpA` but not the other two samples, and then also the `count` step which
depends on all files.
]

---

## Modifying an input file (cont.)

And if we rerun Snakemake, it will indeed run those three jobs:  


```sh
$ snakemake -j1 -pr
#&gt; Building DAG of jobs...
#&gt; Using shell: /usr/bin/bash
#&gt; Provided cores: 1 (use --cores to define parallelism)
#&gt; Rules claiming more threads will be scaled down.
#&gt; Job counts:
#&gt;         count   jobs
#&gt;         1       all
#&gt;         1       count
#&gt;         1       map
#&gt;         1       trim
#&gt;         4
#&gt; 
#&gt; [Tue Apr  6 09:48:58 2021]
#&gt; rule trim:
#&gt;     input: data/smpA.fastq
#&gt;     output: res/smpA_trim.fastq
#&gt;     jobid: 5
*#&gt;     reason: Updated input files: data/smpA.fastq
#&gt; [...]
```

---
class: center middle inverse

# Questions?

-----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Output files in the face of errors 

Another thing to note is that we do have an output file `res/smpA.bam`:

```sh
$ ls res
#&gt; res/smpA.bam
$ cat res/smpA.bam
#&gt; BAM from FASTQ res/smpA_trim.fastq :
```

Recall that the contents of the "mapping" script is:

```sh
echo "BAM from FASTQ $1 :" &amp;&amp; cat $1
```

The error occurred in the second command, where it tried to print the contents
of the trimmed FASTQ file to screen (`cat $1`), which did not exist.

--

However, the first line `BAM from FASTQ $1` was still printed to the file,  
and **now we have an incomplete output file** that we best manually
remove before it confuses or misleads us later.

**Snakemake can remove such files for us automatically**,
but we will need to provide it with more information about output files!

---

## Standard error

Finally, it is also worth noting that the error:

```sh
#&gt; cat: res/smpA_trim.fastq: No such file or directory
```

... which was directly produced by out script, was kind of buried among all
other Snakemake output.

.content-box-q[
Why did this error not go into the output file `res/smpA.bam`?
]

--

.content-box-answer[
Because with our shell command, we redirected the standard output to that file
(with `&gt;`), but we did not redirect the standard error (`2&gt;`):

```sh
shell: "scripts/map.sh res/smpA_trim.fastq &gt; res/smpA.bam"
```

You'll see how to **redirect standard error to log files** in the exercises.
]


## Visualizing the workflow again (cont.)

- Create a workflow diagram before running Snakemake:

  ```sh
  $ rm res/*    # We first remove earlier output files
  
  $ snakemake --dag | dot -T svg &gt; workflow/DAGs/v3a.svg 
  ```

- Run Snakemake:

  ```sh
  $ snakemake -j1 -pq
  ```

- Create a workflow diagram after running Snakemake:

  ```sh
  snakemake --dag | dot -T svg &gt; workflow/DAGs/v3b.svg
  ```

---

## Visualizing the workflow again (cont.)

.pull-left[
.center[**Before we run the workflow:**]
&lt;p align="center"&gt;
&lt;img src=img/v3a.svg width=40%&gt;
&lt;/p&gt;
]

.pull-right[
.center[**After we run the workflow:**]
&lt;p align="center"&gt;
&lt;img src=img/v3b.svg width=40%&gt;
&lt;/p&gt;
]

---

## Snakemake's glob_wildcards() function

.content-box-info[
The wildcards are stored in `.smp` within the wildcard object
to allow you to define multiple wildcards &amp;ndash; for example:

```python
&gt;&gt;&gt; !ls data
#&gt; A_R1.fastq.gz A_R2.fastq.gz B_R1.fastq.gz B_R2.fastq.gz

&gt;&gt;&gt; glob_wildcards("data/{sample}_{read}.fastq.gz").sample
#&gt; ['A', 'A', 'B', 'B']
&gt;&gt;&gt; glob_wildcards("data/{sample}_{read}.fastq.gz").read
#&gt; ['R1', 'R2', 'R1', 'R2']
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "rainbow",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
