---
title: "Week 13 - Reproducible workflows with Snakemake"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "default-fonts", "slides.css", "slides_copy.css"]
    lib_dir: libs
    nature:
      highlightStyle: rainbow
      highlightLines: true
      countIncrementalSlides: false
---
class:inverse middle center

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(eval = FALSE)

icon::fa("user-edit")
```

```{r xaringan-extra, echo=FALSE, eval=TRUE}
#xaringanExtra::use_scribble()
#xaringanExtra::use_panelset()
#xaringanExtra::use_clipboard()
#xaringanExtra::use_search(show_icon = TRUE)
```

# *Week 13 &ndash; <br> Reproducible workflows with Snakemake*

----

# IV: Material from the exercises

<br> <br> <br> <br> <br>

### Jelmer Poelstra
### Last updated: `r Sys.Date()`

---
class: inverse middle center

# Overview

----

.left[
- #### Specifying computational resources
- #### Log files
- #### Using programs where you don't specify output files
- #### "Target rules may not contain wildcards"
- #### Running Snakemake on a cluster
]

---
class: inverse middle center

# Specifying computational resources

----

<br> <br> <br> <br>

---

## Specifying computational resources

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

<br>

- The `-j`/`--jobs` option that we (have to!) specify on the command-line.
  This tells Snakemake the maximum number of "jobs", i.e. processes,
  that it can have running at any given time.
  
  For example, if one rule is being run for 5 samples separately and another
  rule is being run on all samples together, there are 6 jobs running.
 
---

## Specifying computational resources (cont.)

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

<br>

- A `threads` key that we can add to any rule: this will tell Snakemake
  how many threads (~ cores) it should use for any *single job* for that rule.
  
  This is very much like the `-c` / `--cpus-per-task` flag for SLURM jobs,
  and is useful to set to >1 for heavy computational jobs.
  
  Generally, we would also be telling the program itself about the number of
  threads, often using a `-T` flag: 

  ```python
  rule STAR:
        threads: 8
        shell: "STAR --runThreadN {threads} ..."
  ```

---

## Specifying computational resources (cont.)

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

- Finally, we can add a **`resources` key** with arbitrary resource
  key-value pairs to any rule.
  
  This is useful when submitting jobs to a cluster, in which case the resource
  keys can be *mapped to SLURM keys*, as we'll see in a bit.

---
class: inverse middle center

# Log files

----

<br> <br> <br> <br>

---

## Log files

Any standard output printed by your commands or the scripts/programs being run
are simply printed to screen, amid all of Snakemake's logging.

This output to screen is also saved to file, but as it can get pretty chaotic,
it is better to save such output separately for each job.

<br>

For example, we may be inclined to do the following for a script/program that:

- Saves its output to file, and prints logging/errors to screen
  (standard out and/or standard error):

  ```python
  shell: "myscript.py -i {input} -o {output} &> myscript.log"
  ```

- Prints the main output to standard out, and logging/errors to standard error:

  ```python
  shell: "myscript.py -i {input} > {output} 2> myscript.log"
  ```

---

## Log files (cont.)

But should we also tell Snakemake explicitly about such a file,
like we do for `input` and `output` files?
**Yes, but it's best to use a separate key for this: `log`.**

This is convenient because Snakemake treats `log` files differently than regular
output files: if a job fails, Snakemake will delete its regular output files
<sup>[1]</sup>, but not the log files.

Therefore, you can use the log files for troubleshooting.

Example usage of a `log` key:

```python
rule myscript:
    #...
    log: logs/myscript_{sample}.log
    shell: "myscript.py -i {input} > {output} 2> {log}"
```

.footnote[
<sup>[1]</sup> Since such files are likely to be incorrect/incomplete.
If you do need these for  
&nbsp; &nbsp; &nbsp; troubleshooting, you can run Snakemake with the
`--keep-incomplete` option.
]

---

## Using programs where you don't specify output files

For fairly many programs, you don't explicitly define the names of output files,
but the program will just output files with names similar to the input file names.

For instance, when we run FastQC:

```sh
fastqc -o results/fastqc sampleA_R1.fastq.gz
```

We are only specifying an output dir, and FastQC will put output files in there:

```sh
ls my_outdir
#> sampleA_R1.fastqc.html sampleA_R1.fastqc.zip
```

**How do we create a rule for such programs?**

---

## Using programs where you don't specify output files

Should we just omit the output, since we don't need to define it anyway?

```python
rule fastqc:
    input: data/{sample}.fastq.gz
    shell: "fastqc -o results/fastqc"
```

--

.content-box-q[
What would be some problems with this approach?
]

--

Because Snakemake works backwards, that is, it figures out what it needs to do
in order to produce the files mentioned in `input` and `output`:

- It will never see a reason to run the current `rule fastqc`
  (though we could still run it using `snakemake -j fastqc`).

- If a next step depends on the output of FastQC (like MultiQC does),
  Snakemake cannot make this connection:
  remember, **relationships between rules are *inferred* by Snakemake**,
  not stated explicitly.

- Snakemake can't fully check if the rule ran successfully!

---

## Using programs where you don't specify output files

Instead, we should still use an `output` directive:
even though the value is not used by the command itself,
it will be used by Snakemake to infer relationships between rules and to check
whether the rule ran successfully:

```python
rule fastqc:
    input: data/{sample}.fastq.gz
    output:
        "{sample}_R1.fastqc.html",
        "{sampleA}_R1.fastqc.zip"
    shell: "fastqc -o results/fastqc"
```

In such cases, it's not necessarily critical to specify all (possible) output
files, just the ones deemed necessary for the purposes mentioned above.

--

.content-box-info[
Alternatively, you can specify a **directory** rather than files as the output.
This may make sense if the names of the output files are unpredictable or
otherwise unknown.
But this only makes sense if each sample has its own output directory!

```python
output: directory("results/fastqc/{sample}")
```
]

---
class: middle inverse center

# "Target rules may not contain wildcards"

----

<br> <br> <br> <br>

---

## "Target rules may not contain wildcards"

Let's return to the last Snakefile (#7) from the previous slide deck:

```python
SAMPLES = glob_wildcards("data/{smp}.fastq").smp

rule all:
    input: "res/count_table.txt",

rule trim:
    input: "data/{smp}.fastq",
    output: "res/{smp}_trim.fastq",
    shell: "scripts/trim.sh {input} > {output}"

rule map:
    input: "res/{smp}_trim.fastq",
    output: "res/{smp}.bam",
    shell: "scripts/map.sh {input} > {output}"

rule count:
    input: expand("res/{smp}.bam", smp=SAMPLES),
    output: "res/count_table.txt",
    shell: "scripts/count.sh {input} > {output}"
```

---

## "Target rules may not contain wildcards"

What if we now just want to run the rule `trim`?

```python
rule trim:
    input: "data/{smp}.fastq",
    output: "res/{smp}_trim.fastq",
    shell: "scripts/trim.sh {input} > {output}"
```

```sh
snakemake -j1 count_words
#> WorkflowError:
#> Target rules may not contain wildcards. Please specify concrete files or a rule without wildcards.
```

The problem here is that ...

Note that this is also a common error to get when building your workflows and
wanting to run the entire thing.

---

## "Target rules may not contain wildcards"

If we did want to **run just this specific rule with wildcards**, we could:

- Specify one or more specific output files:

```sh
snakemake -j1 res/bookA_cnt.txt
snakemake -j1 res/bookB_cnt.txt res/bookC_cnt.txt
```

- Create a rule that triggers execution of our target rule by listing all its
  output files:

```sh
rule trigger_count_words:
    input: expand("res/{book}_cnt.txt", book=BOOKS)
```        

---
class: inverse middle center

# Running Snakemake on a cluster

----

## For us: at OSC

<br> <br> <br> <br>

---

## Running Snakemake on a cluster

Snakemake can automatically submit SLURM jobs to the cluster for you!

At its most basic, all you need to do is add  `--cluster sbatch`...:

```sh
snakemake -j100 --cluster sbatch
```

...and every job (process) in your workflow will be submitted.  
Here, we also set `-j` to 100 to allow for a maximum of 100 jobs at a time.

<br>

However, because we always need to specify the project at OSC  
(`-A` / `--account`), we should add this, too:

```sh
snakemake -j100 --cluster "sbatch --account=PAS1855"
```

If you need more non-default submission parameters, as is quite common,
it becomes cumbersome to pass these all these options at the command-line.  

*The solution is to use a "profile".*

---

## Using a "profile"

To use a profile, we should **create a directory**.
The name of this directory is arbitrary,
but since we are using it in the context of providing settings for SLURM jobs,
something like `slurm_profile` would make sense:

```sh
mkdir slurm_profile
```

Inside this directory, we should create a file called `config.yaml`:

```sh
touch slurm_profile/config.yaml
```

---

## config.yaml inside the profile directory

In the `config.yaml`, we can provide a string to the `cluster` key,
just like we did previously with the `--cluster` argument on the command-line:

```YAML
cluster: "sbatch --account={resources.account}
                 --time={resources.time_min}
                 --mem={resources.mem_mb}
                 --cpus-per-task={resources.cpus}
                 --output=logs/slurm-{rule}_{wildcards}.out"

default-resources: [cpus=1, mem_mb=4000, time_min=5, account=PAS1855]
```

- We're using `{resources.<resource-name>}` instead of actual values in the
  `cluster` key.
  
- Then, the values for each `<resource-name>` are specified for the
  `default-resources` key.

This setup is convenient because it allows us, for instance, to also 
**refer to the same resources in the Snakefile to set rule-specific values**
(more later).

---

## config.yaml inside the profile directory (cont.)

`config.yaml` can contain not just cluster settings,
but anything that can be set with command-line options.

We can take that opportunity to also:
- Specify the number of jobs.
- Make sure Snakemake uses Conda.
- Make Snakemake wait longer (30 seconds) for output files to appear,
  since I've had errors with shorter latency times, while the files were there.

--

```YAML
jobs: 100
use-conda: true
latency-wait: 30
```

.content-box-info[
Just note that the key-value syntax is that of YAML and therefore slighly
different from when specifying this at the command line:

- `use-conda: true` instead of `--use-conda`
  (and note the lowercase spelling of `true` in YAML format)
- `jobs: 25` instead of `-j25` or `--jobs 25`.
]

---

## config.yaml inside the profile directory (cont.)

Our full `config.yaml` file:

```YAML
cluster: "sbatch --account={resources.account}
                 --time={resources.time_min}
                 --mem={resources.mem_mb}
                 --cpus-per-task={resources.cpus}
                 --output=logs/slurm-{rule}_{wildcards}.out"
default-resources: [cpus=1, mem_mb=1000, time_min=5, account=PAS1855]
jobs: 100
latency-wait: 30
use-conda: true
```

--

.content-box-warning[
If you are specifiying a *directory* that the SLURM log files should be put in,
as we are here, make sure that this directory exists!
Snakemake will not create it and mysterious failures will occur!

```sh
mkdir logs
```
]

---

## Running Snakemake with a profile

Now that we have our profile set up, in order to run Snakemake with all
the settings specified in `config.yaml` inside the `slurm_profile` directory
<sup>[1]</sup>:

```sh
snakemake --profile slurm_profile
```

.footnote[
<sup>[1]</sup> Since we specified the mandatory `-j`/`--jobs` argument
and `--use-conda` in the  
&nbsp; &nbsp; profile as well,
we no longer need to add those at the command-line.
]

---

## "Local rules" for jobs not to be submitted 

In practice, you may not want to submit a cluster job for every rule.

For instance, `rule all` *is* a Snakemake job, but it doesn't actually run
anything the way we have set it up.
Additionally, you may have some very lightweight cleaning/logging rules.

<br>

To tell Snakemake that certain rules should not be submitted to the cluster,
include a comma-separated list of rules near the top of your Snakefile with
the `localrules` key:

```python
localrules: all, clean
```

---

## Rule-specific resource settings other than threads

We can use a `resources` key for any rule to specify (mostly) arbitrary
key-value pairs with resources:

```python
rule heavy_stuff:
    input: ...
    output: ...
    resources: mem_mb=50000
    shell: ...
```

--

These are arbitrary in the sense that `mem_mb` will not directly set the actual
maximum memory usage,
but they refer to the same keys as used in our `config.yaml`:

```YAML
cluster: "sbatch --mem={resources.mem_mb} ..."
default-resources: [mem_mb=1000, ...]
```

Therefore, setting `resources: mem_mb=50000` for `rule heavy_stuff`  
**will override the default value of `1000` and pass that on the SLURM job request.**

---

## Running the main Snakemake process as a job

For small workflows that can be run on one node or less than that,
you can **run Snakemake as a single SLURM job**,
either on an interactive node (especially if the workflow is particularly small)
or by submitting a script with `sbatch`.

For example, we can submit the follow script to SLURM with `sbatch`:

```sh
#!/bin/bash
set -e -u -o pipefail
  
#SBATCH --account=PAS1855
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=3
#SBATCH --cpus-per-task=1
  
snakemake -j"$SLURM_NTASKS" -p  
```

---

## Side note: Advanced cluster configuration

.content-box-info[
It is possible to get quite a bit more advanced with cluster configuration.
For example:

- In our `config.yaml` file, we could also use the `resources` key
  (vs `default-resources` earlier) to specify a maximum *total* amount of
  resources that can be used by all jobs together:

  ```YAML
  resources: [cpus=100, mem_mb=1000000]
  ```

- We could pass a script to the `--cluster-status` option on the command-line
  to improve detection of cluster job failure.
  There is a `Snakemake-Profiles` GitHub account that includes downloadable
  settings for SLURM
  [here](https://github.com/Snakemake-Profiles/slurm).
]
