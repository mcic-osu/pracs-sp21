<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 11 - Python: Scientific computing</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
    <link rel="stylesheet" href="slides_copy.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class:inverse middle center





# *Week 11 - Python: Scientific computing*

----

# III: BioPython

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

### Jelmer Poelstra
### 2021/03/25 (updated: 2021-03-21)

---

## What is BioPython?

BioPython is a project with a set of related modules to enable the
use of Python for various **bioinformatics tasks**, such as parsing and
processing bioinformatics file formats, access to online services like NCBI
Entrez and BLAST, and so on.

&lt;br&gt;

Today, we'll work through 4 small sample applications:

1. Finding and retrieving sequences from NCBI (CSB 6.4.1)

2. Reading and writing sequence data (CSB 6.4.2)

3. Programmatic BLAST search (CSB 6.4.3)

4. Querying PubMed (CSB 6.4.4)

---
class: center middle inverse

# BioPython (CSB 6.4)

-----

# I: Retrieving sequences from NCBI (6.4.1)

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Using BioPython to inferface with NCBI databases

We already downloaded some data from NCBI manually in the exercises for
week 7 (Bioinformatics Data).

If we would regularly need to do so, or would need to download data from many
organisms, it would be much better to do this programmatically.

Luckily, we can use NCBI's **"Entrez Programming Utilities"** via 
the `Entrez` module in BioPython. 

--

&lt;br&gt;

- We start by importing the module &amp;ndash; note that BioPython modules are
  imported using `from Bio import &lt;focal-module&gt;`:
  
  ```python
  from Bio import Entrez
  ```

- As another setup step,
  we should provide our e-mail address to let NCBI know who we are:

  ```python
  Entrez.email = "me.1@osu.edu"  # Replace by your email address
  ```

---

## The inquisitive shrew mole 

Let's say we would like to explore available DNA sequences from the Inquisitive
Shrew Mole, *Uropsilus investigator*.

&lt;br&gt;

&lt;figure&gt;
&lt;p align="center"&gt;
&lt;img src=img/inquisitive-shrew-mole.jpg width="55%"&gt;
&lt;figcaption&gt;The Inquisitive Shrew Mole is endemic to Yunnan, China. (&lt;a href="https://theverybesttop10.com/rarest-species-of-moles-voles-and-shrews/"&gt;Image source&lt;/a&gt;)&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

---

## Perform the search

We can perform the search using the **`Entrez.esearch()`** function:

```python
handle = Entrez.esearch(db = "nuccore",
                        term = ("Uropsilus investigator[Organism]"),
                        retmax = 200)
```

  - NCBI makes several databases available through Entrez,
    and we searched the **"Nucleotide" (or `nuccore`) database**,
    which includes GenBank and RefSeq data, using the `db` argument.
  
  - We created a "handle" for the results
    (similar to *file handles* earlier).
  
  - For NCBI searches, we can narrow down results by adding keywords between square
    brackets, like `[Organism]`, after our search term.&lt;sup&gt;[1]&lt;/sup&gt;
  
  - We set `RetMax` to 200 (default is 20) to get all the sequence identifiers
    (this can be a bit of trial-and-error or you can start veru high).

.footnote[&lt;sup&gt;[1]&lt;/sup&gt;See the Nucleotide ["Advanced Search Builder"](https://www.ncbi.nlm.nih.gov/nuccore/advanced)
for all possible keywords.]

---

## Save and check the search results

- Read the results and close the search handle:

  ```python
  search_results = Entrez.read(handle)
  handle.close()
  ```

&lt;br&gt;

- Our results are returned in the form of a *dictionary*,
  so let's look at the keys:
  
  ```python
  search_results.keys()
  #&gt; dict_keys(['Count', 'RetMax', 'RetStart', 'IdList',
  #&gt;            'TranslationSet', 'TranslationStack',
  #&gt;             'QueryTranslation'])
  ```
  
---

## Looking at the results

- How many sequences did we find?  
  
  ```python
  search_results["Count"]
  '126'   # Has increased from '71' in the book!
  ```
  
- What is the list of GenBank identifiers?

  ```python
  id_list = search_results["IdList"]
  
  print(id_list)
  #&gt; ['524853022', '555947199', '555947198', ... , '555946814']
  
  len(id_list)   # Making sure we got all 126 IDs
  #&gt; '126' 
  ```

---

## Downloading the sequences and &lt;br&gt; writing them to a FASTA file

- We'll now use the retrieved GenBank IDs (`id = id_list`) to download the
  sequences in FASTA format (`rettype = "fasta"`):

  ```python
  search_handle = Entrez.efetch(db = "nuccore",
                                  rettype = "fasta",
                                  id = id_list)
  ```

--

- Next, we can write the sequences to file:

  ```python
  with open("Uropsilus_seq.fasta", "w") as fhandle_out:
         for line in search_handle:
             fhandle_out.write(line)
  search_handle.close()
  ```

&lt;br&gt;

- **The next step is to read our FASTA file back in, properly parsed,
  using the `SeqIO` module.**

---

class: center middle inverse

# BioPython (CSB 6.4)

-----

# II: Reading and writing sequence data &lt;br&gt; using *SeqIO* (6.4.2)

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Reading a FASTA file with SeqIO

- We start by importing the BioPython `SeqIO` module:

  ```python
  from Bio import SeqIO
  ```

&lt;br&gt;

- With `SeqIO.parse()`, we can create an object called a `SeqRecord` iterator
  that we can then loop over to retrieve our sequences.
  
  ```python
  records = SeqIO.parse("Uropsilus_seq.fasta", "fasta")
  ```
  
  This model is similar to the *file handles* we worked with earlier and is
  particularly useful for very large FASTA files,
  so we don't have to load them into memory.
  
---

## Reading a FASTA file with SeqIO (cont.)

- Each FASTA record has several attributes, including:
  - `description` &amp;ndash; everything after the `&gt;`
  - `name` &amp;ndash; first word after the `&gt;`
  - `seq` &amp;ndash; the sequence

&lt;br&gt;

&lt;p align="center"&gt;
&lt;img src=img/FASTA.png width="100%"&gt;
&lt;/p&gt;

---

## Reading a FASTA file with SeqIO (cont.)

- For each record, let's print the `description` and the length (in bp)
  of `seq`:

  ```python
  for record in records:
        print(record.description, '\n', len(record.seq), '\n')
  
  #&gt; KC516837.1 Uropsilus investigator isolate A11 apolipoprotein B (ApoB) gene, partial cds
  #&gt; 573 
  #&gt;
  #&gt; KC516819.1 Uropsilus investigator voucher mlxs331 cytochrome c oxidase subunit I (COI) gene, partial cds, alternatively spliced; mitochondrial
  #&gt; 912 
  #&gt;
  #&gt; KC516818.1 Uropsilus investigator voucher mlxs022 cytochrome c oxidase subunit I (COI) gene, partial cds, alternatively spliced; mitochondrial
  #&gt; 912 
  #&gt; [...]
  ```

---

## Selecting only sequences for the BMI1 genes

Next, say that we to:
  - Select only records originating from a specific gene
  - Only take the first 100 bp of sequence for each record

&lt;br&gt;

.content-box-info[
This is a quite apt example because parsing and subsetting FASTA files
with *shell tools* is not as easy as you may expect.

This is because each FASTA record spans multiple lines &amp;ndash;
and the *sequence* for an individual records may or
may not itself also be spread across multiple lines.
]

---

## Selecting only sequences for the BMI1 genes

Next, say that we to:
  - Select only records originating from a specific gene
  - Only take the first 100 bp of sequence for each record

```python
output_handle = open("Uropsilus_BMI1.fasta", "w")

for record in SeqIO.parse("Uropsilus_seq.fasta", "fasta"):
    
    if record.description.find("BMI1") != -1:
        print(record.id)
        short_seq = record[:100]  # Take the first 100 bases
        SeqIO.write(short_seq, output_handle, "fasta")
        
output_handle.close()
```

We used the string method `find()` to match "*BMI1*",
making use of the fact that it returns `-1` when no match is found.

--

.content-box-info[
Next week, we'll learn how to use the
regular expression module `re` to do this more gracefully and flexibly.
]

---

class: center middle inverse

# BioPython (CSB 6.4)

-----

# III: Programmatic BLAST search (6.4.3)

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## NCBI BLAST

The **Basic Local Alignment Search Tool (BLAST)** finds regions of similarity
between biological sequences,
and is one of the most widely used bioinformatics tools.

You may know it by its web interface, where you can paste in or upload some
sequences, and then "BLAST them" against a database you can specify.

&lt;figure&gt;
&lt;p align="center"&gt;
&lt;img src=img/blast_screenshot.png width="80%"&gt;
&lt;figcaption&gt;Screenshot from &lt;a href="https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&amp;PAGE_TYPE=BlastSearch&amp;LINK_LOC=blasthome"&gt;NCBI BLAST&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

---

## Getting set up for BLAST with the Blast module

Using the web interface may be convenient when you just have one or a few sequences,
but it is not very reproducible, tedious to repeat, and unsuitable for automation.

Luckily, Biopython provides the module `Bio.Blast` which we can use to run a
BLAST search against the NCBI's online databases programmatically.&lt;sup&gt;[1]&lt;/sup&gt;

.footnote[
&lt;sup&gt;[1]&lt;/sup&gt; Note, there is also a *command-line* BLAST tool.
]

--

```python
# from Bio import SeqIO   # Should already be loaded
# from Bio import Entrez  # Should already be loaded
from Bio.Blast import NCBIWWW, NCBIXML
```

We imported just two of its functions:
  
  - `NCBIWWW` for access to NCBI's BLAST server &amp;ndash;
     the BLAST analysis is still being performed there.
  
  - `NCBIXML` to parse the XML format in which our results will be returned.

---

## Storing all FASTA records in a list

We will start by parsing our FASTA file again with `SeqIO`.

This time, however, we will read the entire file into memory at once
by converting the `SeqRecord` iterator to a list:

```python
records = list(SeqIO.parse("Uropsilus_BMI1.fasta", "fasta"))
```

--

What does this list look like? Let's print the first 2 items:

```python
records[0:2]
#&gt; [SeqRecord(seq=Seq('TATTATGCTGTTTTGTGAACCTGTAGAAAACAAGTGCTTTTTATCTTGAAATTC...CCA', SingleLetterAlphabet()), id='KF778086.1', name='KF778086.1', description="KF778086.1 Uropsilus investigator voucher KIZ:020539 polycomb ring finger oncoprotein (BMI1) gene, 3' UTR", dbxrefs=[]),
#&gt; SeqRecord(seq=Seq('TATTATGCTGTTTTGTGAACCTGTAGAAAACAAGTGCTTTTTATCTTGAAATTC...CCA', SingleLetterAlphabet()), id='KF778085.1', name='KF778085.1', description="KF778085.1 Uropsilus investigator voucher KIZ:020527 polycomb ring finger oncoprotein (BMI1) gene, 3' UTR", dbxrefs=[])]
```

From this list, we can still extract record attributes &amp;ndash;
for instance, we can print the `id` and `seq` for the 4th record:

```python
print(records[3].id, " ", records[3].seq)
#&gt; KF778083.1   TATTATGCTGTTTTGTGAACCTGTAGAAAACAAGTGCTTTTTATCTTGAAATTCAACAAATGGAAAGAATATGCATAGAATAATGCATTCTATGTAGCCA
```

---

## Run the BLAST search

For our BLAST search, we will use the nucleotide database (`nt`)
with the `blastn` algorithm, the BLAST variant for standard nucleotide to
nucleotide searches (other options are `blastp`, `blastx`, `tblastn`, and `tblastx`).

&lt;br&gt;

The `qblast()` function requires three arguments:
  - The program &amp;ndash; `blastn` for us
  - The database &amp;ndash; `nt` for us
  - The query sequence &amp;ndash; the 4th record from our FASTA file

```python
Entrez.email = "me.999@osu.edu"

result_handle = NCBIWWW.qblast("blastn", "nt", records[3].seq)
```

---

## Write the results to a file

Now, we will write our results, which are in XML format,
to a file, and then close the result handle:

```python
with open("my_blast.xml", "w") as fhandle:
    fhandle.write(result_handle.read())

result_handle.close()
```

---

## Parse the XML file

We will parse our XML file with BLAST results using the `NCBIXML`
parser:&lt;sup&gt;[1]&lt;/sup&gt;

.footnote[&lt;sup&gt;[1]&lt;/sup&gt; Because we our query consisted only of a single sequence,
we could use `NCBIXML.read()`. For multiple sequences, you should use `NCBIXML.parse`.]

```python
result_handle = open("my_blast.xml")
blast_records = NCBIXML.read(result_handle)
```

---

## Processing the BLAST results

Next, we loop through the individual alignment hits and then for each hit
through the "High-Scoring Pairs" (HSPs, subsequences with a good match).

For each High-Scoring Pair, we check whether the match is good enough
according to an arbitrary E-value (`E_VALUE_THRESH`) and length (`LEN_THRESH`)
that we set.

```python
E_VALUE_THRESH = 0.04
LEN_THRESH = 3000

for align in blast_records.alignments:
    
    for hsp in align.hsps:
        
        if hsp.expect &lt; E_VALUE_THRESH and align.length &gt; LEN_THRESH:
            
            print("****Alignment****")
            print("sequence:", alignment.title)
            print("length:", alignment.length)
            print("E value:", hsp.expect)
            print(hsp.query[0:75] + "...")
            print(hsp.match[0:75] + "...")
            print(hsp.sbjct[0:75] + "...")
```

---

## Processing the BLAST results

```python
E_VALUE_THRESH = 0.04
LEN_THRESH = 3000

for align in blast_records.alignments:
    
    for hsp in align.hsps:
        
        if hsp.expect &lt; E_VALUE_THRESH and align.length &gt; LEN_THRESH:
            
            print("****Alignment****")
            print("sequence:", alignment.title)
            print("length:", alignment.length)
            print("E value:", hsp.expect)
            print(hsp.query[0:75] + "...")
            print(hsp.match[0:75] + "...")
            print(hsp.sbjct[0:75] + "...")
#&gt; ****Alignment****
#&gt; sequence: gi|1304911126|ref|XM_006933246.4| PREDICTED: Felis catus BMI1 proto-oncogene, polycomb ring finger (BMI1), transcript variant X3, mRNA
#&gt; length: 3523
#&gt; E value: 2.25861e-42
#&gt; TATTATGCTGTTTTGTGAACCTGTAGAAAACAAGTGCTTTTTATC...
#&gt; |||||||||||||||||||||||||||||||||||||||||||||...
#&gt; TATTATGCTGTTTTGTGAACCTGTAGAAAACAAGTGCTTTTTATC...
#&gt; [...]
```

---

class: center middle inverse

# BioPython (CSB 6.4)

-----

# IV: Querying PubMed (6.4.4)

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## PubMed search

Using the `Entrez.esearch()` function we saw earlier,
we can search any NCBI database,
including PubMed, which contains scientific literature.

By way of example, we will search for any papers on *Drosophila* that mention
the gene "*spaetzle*" anywhere in the title or abstract:&lt;sup&gt;[1]&lt;/sup&gt;

.footnote[&lt;sup&gt;[1]&lt;/sup&gt;See [here](https://pubmed.ncbi.nlm.nih.gov/help/#author-search)
for PubMed search options.]

```python
from Bio import Entrez
Entrez.email = "me.999@osu.edu"

handle = Entrez.esearch(db = "pubmed",
                        term = ("spaetzle[Title/Abstract] AND Drosophila[ALL]"),
                        usehistory = "y")
record = Entrez.read(handle)
handle.close()                        
```                        

---

## PubMed search

Using the `Entrez.esearch()` function we saw earlier,
we can search any NCBI database,
including PubMed, which contains scientific literature.

By way of example, we will search for any papers on *Drosophila* that mention
the gene "*spaetzle*" anywhere in the title or abstract:&lt;sup&gt;[1]&lt;/sup&gt;

```python
from Bio import Entrez
Entrez.email = "me.999@osu.edu"

handle = Entrez.esearch(db = "pubmed",
                        term = ("spaetzle[Title/Abstract] AND Drosophila[ALL]"),
                        usehistory = "y")
record = Entrez.read(handle)
handle.close()                        
```                        

- We used `usehistory = "y"`, which will allows us to refer back to our search
  to fetch the titles and abstracts by saving `WebEnv` and `QueryKey`:

  ```python
  webenv = record["WebEnv"]
  query_key = record["QueryKey"]
  ```

---

## PubMed search (cont.)

- How many hits did we get?

  ```python
  record["Count"]
  #&gt; '15'
  ```
  
  We found 15 records (up from 13 in the book) that contained the words
  "*spaetzle*" and "*Drosophila*".

--

- We can now fetch the titles and abstracts:

  ```python
  handle = Entrez.efetch(db = "pubmed",
                           rettype = "medline", retmode = "text",
                           webenv = webenv, query_key = query_key)
  data = handle.read()
  handle.close() 
  ```

--

- Finally, we write the results to file:

  ```python
  out_handle = open("Spaetzle_abstracts.txt", "w")
  out_handle.write(data)
  out_handle.close()
  ```

---

## PubMed search (cont.)

- Let's have a look at the results:

  ```python
  !cat Spaetzle_abstracts.txt
  ```
  
- With a simply `grep` command, we can just see lines
  (and some context with `-C 1`) with the word "*Spaetzle*":  

  ```python
  !grep -i "spaetzle" -C 1 Spaetzle_abstracts.txt
  
  #&gt;     leading to ventrally-restricted expression of the sulfotransferase Pipe. These
  #&gt;    events promote the ventral processing of Spaetzle, a ligand for Toll, which
  #&gt;    ultimately sets up the embryonic dorsal-ventral axis. We then describe the
  #&gt; --
  #&gt; DP  - 2019 Nov 12
  #&gt; TI  - Dynamics of Spaetzle morphogen shuttling in the Drosophila embryo shapes
  #&gt;    gastrulation patterning.
  #&gt; --
  #&gt;    The dynamics indicate that a sharp extracellular gradient is formed through
  #&gt;    diffusion-based shuttling of the Spaetzle (Spz) morphogen that progresses through
  #&gt;    several nuclear divisions. Perturbed shuttling in wntD mutant embryos results in 
  ```

---

## PubMed search (cont.)

Alternatively, we could use regular expressions in Python to nicely get each
*sentence* with "*Spaetzle*" along with the PubMedID for the publication:

```python
import re
with open("Spaetzle_abstracts.txt") as datafile:
    
    pubmed_input = datafile.read()
    # Titles and abstracts on one line: delete newlines + 6 spaces:
    pubmed_input = re.sub(r"\n\s{6}", " ", pubmed_input)

    for line in pubmed_input.split("\n"):
        if re.match("PMID", line):
            PMID = re.search(r"\d+", line).group()
        if re.match("AB", line):
            spaetzle = re.findall(r"([^.]*?Spaetzle[^.]*\.)", line)
            if spaetzle:
                print("PubMedID: ", PMID, " ", spaetzle)
#&gt; PubMedID:  32591083   [' These events promote the ventral processing of Spaetzle, a ligand for Toll, which ultimately sets up the embryonic dorsal-ventral axis.']
#&gt; PubMedID:  31719046   ['  The dynamics indicate that a sharp extracellular gradient is formed through diffusion-based shuttling of the Spaetzle (Spz) morphogen that progresses through several nuclear divisions.']
#&gt; PubMedID:  27314646   [' While cytokines activating immune responses,  such as Spaetzle or Unpaired-3, have been identified and
```  
  
**We will learn how to do this next week!**

---

## PubMed search (cont.)

While this PubMed search was relatively trivial, you may need to do this kind of
search for a dozen or more genes, and possibly repeat the search periodically.

In that case, using Python to do the searches and parse the results can be a
huge time-saver!

---
class: center middle inverse

# Questions?

-----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "rainbow",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
