<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 13 - Reproducible workflows with Snakemake</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
    <link rel="stylesheet" href="slides_copy.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class:inverse middle center





# *Week 13 &amp;ndash; &lt;br&gt; Reproducible workflows with Snakemake*


----

# III: Miscellaneous &amp; &lt;br&gt; running Snakemake on a cluster

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

### Jelmer Poelstra
### 2021/04/08 (updated: 2021-03-30)

---
class: inverse middle center

# Miscellaneous Snakemake

----

&lt;br&gt;

.left[
- ### Useful command-line options
- ### What will Snakemake run?
- ### Log files
- ### Conda environments
]

---

## Useful command-line options: dry run (-n)

With the `-n` (long form: `--dryrun`) option, Snakemake will not run any of
the actions specified, but it will check which rules/jobs it *would* be running.

--

This is extremely useful to:
  
- Check whether the workflow will run the way you think it will run
  (remember: relationships between rules are not explicitly defined...).
    
- Check if anything needs to be done: you may not remember which output files
  are already there, or if an input file has been updated, and this is the
  easiest way to check!
    
- Check if you have no errors in your Snakefile
  (e.g. syntax errors, wildcards that Snakemake can't figure out).

&lt;br&gt;

```sh
snakemake -j1 -n
```

---

## Useful command-line options: &lt;br&gt; reason (-r) and print shell commands (-p)

We have already seen these two options:

- `-r` (long form: `--reason`) to let Snakemake tell you *why* it thinks what it
  should run.

- `-p` (long form: `--printshellcmds`) to print the shell commands
  (action key `shell`) that are being run.

&lt;br&gt;

**These are very useful to also use in combination with the `-n`/`--dryrun` option,
for troubleshooting  and for getting a better intuition for how Snakemake works.**

&lt;br&gt;

```sh
snakemake -j1 -npr
```

---

## Useful command-line options: Miscellaneous

Short  |  Long            | Explanation
-------|------------------|-------------
-      | `--lint`         | Run the Snakemake "linter" on the Snakefile
`-f`   | `--force &lt;rule&gt;` |
`-F`   | `--forceall &lt;rule&gt;` |
`-R`   | `--forcerun`
-      | `--use-conda`    |
-      | `--report`       |
-      | `--archive`      | 

---

## Useful command-line options: Miscellaneous

Overview of options we have seen so far:

Short  |  Long            | Explanation
-------|------------------|-------------
`-q`   | `--quiet`        | Less output, can be useful with `-n` just to get overview of jobs that will be run.
`-p`   | `--printshellcmds` | Print `shell` commands that will be executed.
`-r`   | `--reason`       | Give reason of execution for every job.
`-n`   | `--dryrun`       | Don't run anything, just report what *would* be run.
`-j`   | `--job`          | Max. number of jobs to run simultaneously.
`-s`   | `--snakefile`    | Name of / path to the Snakefile.

---

## What will Snakemake run?

- Snakemake will create an output file, and all its dependencies, if:
  
  - The output file is a command-line target and does not exist.
  
  - The output file is needed by another executed job and does not exist.
  
  - The output file is older than the input file.
  
  - The input file will be updated by other job.
  
  - Execution is enforced with `-f` / `-F` / `-R`.

&lt;br&gt;

- Snakemake will not create output files *even if* (!):

  - Code in the rule (or elsewhere in the Snakefile) has changed.
  
  - Additional input files have been added.

---

## Using log files

Any standard output printed by your commands or the scripts/programs being run
are simply printed to screen, amid all of Snakemake's logging.

This output to screen is also saved to file, but as it can get pretty chaotic,
it is better to save such output separately for each job.

&lt;br&gt;

For example, we may be inclined to do the following for a script/program that:

- Saves its output to file, and prints logging/errors to screen
  (standard out and/or standard error):

  ```python
  shell: "myscript.py -i {input} -o {output} &amp;&gt; myscript.log"
  ```

- Prints the main output to standard out, and logging/errors to standard error:

  ```python
  shell: "myscript.py -i {input} &gt; {output} 2&gt; myscript.log"
  ```

---

## Using log files (cont.)

But should we also tell Snakemake explicitly about such a file,
like we do for `input` and `output` files?

Yes, but we use a separate key: `log`.

This is convenient because Snakemake treats `log` files differently than regular
output files: if a job fails, Snakemake will delete its regular output files
&lt;sup&gt;[1]&lt;/sup&gt;, but not the log files,
which you can therefore use for troubleshooting.

Example usage of a `log` key:

```python
log: logs/myscript_{wildcard.sample}.log
shell: "myscript.py -i {input} &gt; {output} 2&gt; {log}"
```

.footnote[
&lt;sup&gt;[1]&lt;/sup&gt; Since those are likely to be incorrect/incomplete.
If you do need these for  
&amp;nbsp; &amp;nbsp; &amp;nbsp; troubleshooting, you can run Snakemake with the
`--keep-incomplete` option.
]

---

## Using Conda environments

Snakemake plays well with Conda and with Singularity containers,
and using such software environments can help a lot with making your workflow
functional and reproducible across different hardware environments.

While containers are even better at this, Conda is more lightweight
and will suffice for most purposes.

Snakemake will in fact **create the necessary Conda environments for us**,  
all we need to do is:

- Include a `conda` key in the focal rule,
  where we specify a YAML file with instructions for the environment:

  ```python
  rule fastqc:
      conda: "envs/fastqc-env.yaml"
      # ...other keys...
  ```

- Include the `--use-conda` option in our Snakemake call:

  ```sh
  snakemake -j1 --use-conda
  ```

---

## Using Conda environments (cont.)

Recall that we can create such YAML files from existing Conda environments
using `conda env export`,
but it is also very easy to write a file from scratch.

For instance, for a specific version of FastQC, and specifying `bioconda` as
the channel, the full YAML file would look like this:&lt;sup&gt;[1]&lt;/sup&gt;

```sh
name: fastqc-env
channels:
  - bioconda
dependencies:
  - fastqc=0.11.8
```

.footnote[
&lt;sup&gt;[1]&lt;/sup&gt; For use with Snakemake, the `name` key can also be omitted.  
]

---

## Specifying computational resources

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

&lt;br&gt;

- The `-j`/`--jobs` option that we (have to!) specify on the command-line.
  This tells Snakemake the maximum number of "jobs", i.e. processes,
  that it can have running at any given time.
  
  For example, if one rule is being run for 5 samples separately and another
  rule is being run on all samples together, there are 6 jobs running.
 
---

## Specifying computational resources

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

&lt;br&gt;

- A `threads` key that we can add to any rule: this will tell Snakemake
  how many threads (~ cores) it should use for any *single job* for that rule.
  
  This is very much like the `-c` / `--cpus-per-task` flag for SLURM jobs,
  and is useful to set to &gt;1 for heavy computational jobs.
  
  Generally, we would also be telling the program itself about the number of
  threads, often using a `-T` flag: 

  ```python
  rule STAR:
        threads: 8
        shell: "STAR --runThreadN {threads} ..."
  ```

---

## Specifying computational resources

There are three main things we need to know about when we want to tell Snakemake
about computational resources that it can use:

- Finally, we can add a **`resources` key** with arbitrary resource
  key-value pairs to any rule.
  
  This is useful when submitting jobs to a cluster, in which case the resource
  keys can be *mapped to SLURM keys*, as we'll see in a bit.

---
class: inverse middle center

# Running Snakemake on a cluster

----

## For us: at OSC

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;

---

## Running Snakemake on a cluster

Snakemake can automatically submit SLURM jobs to the cluster for you!

At its most basic, all you need to do is add  `--cluster sbatch`...:

```sh
snakemake -j100 --cluster sbatch
```

...and every job (process) in your workflow will be submitted.  
Here, we also set `-j` to 100 to allow for a maximum of 100 jobs at a time.

&lt;br&gt;

However, because we always need to specify the project at OSC  
(`-A` / `--account`), we should add this, too:

```sh
snakemake -j100 --cluster "sbatch --account=PAS1855"
```

If you need more non-default submission parameters, as is quite common,
it becomes cumbersome to pass these all these options at the command-line.  

*The solution is to use a "profile".*

---

## Using a "profile"

To use a profile, we should **create a directory**.
The name of this directory is arbitrary,
but since we are using it in the context of providing settings for SLURM jobs,
something like `slurm_profile` would make sense:

```sh
mkdir slurm_profile
```

Inside this directory, we should create a file called `config.yaml`:

```sh
touch slurm_profile/config.yaml
```

---

## config.yaml inside the profile directory

In the `config.yaml`, we can provide a string to the `cluster` key,
just like we did previously with the `--cluster` argument on the command-line:

```YAML
cluster: "sbatch --account={resources.account}
                 --time={resources.time_min}
                 --mem={resources.mem_mb}
                 --cpus-per-task={resources.cpus}
                 --output=slurmlogs/slurm-%j_{rule}_{wildcards}.out"

default-resources: [cpus=1, mem_mb=1000, time_min=5, account=PAS1855]
```

- We're using `{resources.&lt;resource-name&gt;}` instead of actual values in the
  `cluster` key.
  
- Then, the values for each `&lt;resource-name&gt;` are specified for the
  `default-resources` key.

This setup is convenient because it allows us, for instance, to also 
**refer to the same resources in the Snakefile to set rule-specific values**
(more later).

---

## config.yaml inside the profile directory (cont.)

`config.yaml` can contain not just cluster settings,
but anything that can be set with command-line options.

We can take that opportunity to also:
- Specify the number of jobs.
- Make sure Snakemake uses Conda.
- Make Snakemake wait longer (30 seconds) for output files to appear,
  since I've had errors with shorted latency times, while the files were there.

--

```YAML
jobs: 100
use-conda: true
latency-wait: 30
```

.content-box-info[
Just note that the key-value syntax is that of YAML and therefore slighly
different from when specifying this at the command line:

- `use-conda: true` instead of `--use-conda`
  (and note the lowercase spelling of `true` in YAML format)
- `jobs: 25` instead of `-j25` or `--jobs 25`.
]

---

## config.yaml inside the profile directory (cont.)

Our full `config.yaml` file:

```YAML
cluster: "sbatch --account={resources.account}
                 --time={resources.time_min}
                 --mem={resources.mem_mb}
                 -c {resources.cpus}
                 -o slurmlogs/slurm-%j_{rule}_{wildcards}.out"
default-resources: [cpus=1, mem_mb=1000, time_min=5, account=PAS1855]
jobs: 100
latency-wait: 30
use-conda: true
```

--

.content-box-warning[
If you are specifiying a *directory* that the SLURM log files should be put in,
as we are here, make sure that this directory exists!
Snakemake will not create it and mysterious failures will occur!

```sh
mkdir slurmlogs
```
]

---

## Running Snakemake with a profile

Now that we have our profile set up, in order to run Snakemake with all
the settings specified in `config.yaml` inside the `slurm_profile` directory
&lt;sup&gt;[1]&lt;/sup&gt;:

```sh
snakemake --profile slurm_profile
```

.footnote[
&lt;sup&gt;[1]&lt;/sup&gt; Since we specified the mandatory `-j`/`--jobs` argument
and `--use-conda` in the  
&amp;nbsp; &amp;nbsp; profile as well,
we no longer need to add those at the command-line.
]

---

## "Local rules" for jobs not to be submitted 

In practice, you may not want to submit a cluster job for every rule.

For instance, `rule all` *is* a Snakemake job, but it doesn't actually run
anything the way we have set it up.
Additionally, you may have some very lightweight cleaning/logging rules.

&lt;br&gt;

To tell Snakemake that certain rules should not be submitted to the cluster,
include a comma-separated list of rules near the top of your Snakefile with
the `localrules` key:

```python
localrules: all, clean
```

---

## Rule-specific resource settings other than threads

We can use a `resources` key for any rule to specify (mostly) arbitrary
key-value pairs with resources:

```python
rule heavy_stuff:
    input: ...
    output: ...
    resources: mem_mb=50000
    shell: ...
```

--

These are arbitrary in the sense that
`mem_mb` will not directly set the actual maximum memory usage,
but they refer to the same keys as used in our `config.yaml`:

```YAML
cluster: "sbatch --mem={resources.mem_mb} ..."
default-resources: [mem_mb=1000, ...]
```

Therefore, setting `resources: mem_mb=50000` for `rule heavy_stuff`  
**will override the default value of `1000` and pass that on the SLURM job request.**


---

## Running the main Snakemake process as a job

### TODO

---

## Side note: Advanced cluster configuration

.content-box-info[
It is possible to get quite a bit more advanced with cluster configuration.
For example:

- In our `config.yaml` file, we could also use the `resources` key
  (vs `default-resources` earlier) to specify a maximum *total* amount of
  resources that can be used by all jobs together:

  ```YAML
  resources: [cpus=100, mem_mb=1000000]
  ```

- We could pass a script to the `--cluster-status` option on the command-line
  to improve detection of cluster job failure.
  There is a `Snakemake-Profiles` GitHub account that includes downloadable
  settings for SLURM
  [here](https://github.com/Snakemake-Profiles/slurm).
]

---
class: center middle inverse

# Questions?

-----

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "rainbow",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
