{
  "articles": [
    {
      "path": "w05_exercises.html",
      "title": "Week 5 exercises",
      "author": [],
      "contents": "\n\nContents\nMain exercises\nBackground\nExercise 1: Setting up\nExercise 2: Create a script to compute stats for a FASTQ file\nExercise 3: Modify the looping script\nExercise 4: Bells and whistles\n\nBonus exercises\nExercise 5: Find the longest file\nExercise 6: Plant-pollinator networks\nExercise 7: Data explorer\n\nSolutions\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5\nExercise 6\nExercise 7\n\n\nThe main exercises will work with some FASTQ files. If you don’t care much for DNA sequence files, and perhaps start to get lost in the technicalities, make sure to carry on to the three bonus exercises.\nMain exercises\nBackground\nThese exercises will work with 6 FASTQ files with sequences from the V4 region of 16S rRNA, generated in a metabarcoding experiment.\nThe FASTQ files come in pairs: for every sample, there is a FASTQ file with forward reads (or “read 1” reads) that contains _R1_ in its filename, and a FASTQ file with corresponding reverse reads (or “read 2” reads) that contain _R2_ in its filename. So, our 6 FASTQ files consist of 3 pairs of files with forward and reverse reads for 3 different biological samples.\nThe sequences were generated by first amplifying environmental samples with a pair of universal 16S primers, and these primer sequences are expected to be present in the FASTQ sequences. You will search for these primer sequences below, and there are two things to be aware of:\nA primer can also be present in the FASTQ sequence as its reverse complement, so we will search for reverse complements too.\nThe primers contain a few variable sites, which are indicated using ambiguity codes. For instance, an R means that the site can be either an A or a G, and an N means that the site can be any of the four bases. See here for a complete overview of these ambiguity codes.\nHere are the primer sequences and their reverse complements1:\nForward primer (“515F”): GAGTGYCAGCMGCCGCGGTAA / TTACCGCGGCKGCTGRCACTC.\nReverse primer (“806R”): ACGGACTACNVGGGTWTCTAAT / ATTAGAWACCCBNGTAGTCCGT.\nExercise 1: Setting up\nCreate a directory for this week’s exercises and move into it.\nIn these exercises, you will be working with and modifying one of the scripts in Buffalo’s Chapter 12, which is printed below. Save this script as fastq_stat_loop.sh.\n#!/bin/bash\nset -e -u -o pipefail\n\n# Specify the input samples file (3rd column = path to FASTQ file):\nsample_info=samples.txt\n\n# Create a Bash array from the third column of \"$sample_info\":\nsample_files=($(cut -f 3 \"$sample_info\"))\n\n# Loop through the array:\nfor fastq_file in ${sample_files[@]}; do\n\n  # Strip .fastq from each FASTQ file, and add suffix:\n  results_file=\"$(basename $fastq_file .fastq)-stats.txt\"\n\n  # Run \"fastq_stat\" on a file:\n  fastq_stat \"$fastq_file\" > stats/$results_file\n\ndone\nThe FASTQ files you’ll work with are inside the directory /fs/ess/PAS1855/data/week05/fastq. Copy these files into an appropriate directory inside your own directory for these exercises, like data/.\n\nExercise 2: Create a script to compute stats for a FASTQ file\nUnfortunately, the fastq_stat program referenced in Buffalo’s script is an imaginary program… So, let’s create a script fastqc_stat.sh that actually produces a few descriptive statistics for a a FASTQC file.\nSet up a script skeleton with the header lines we’ve been discussing: a shebang line and the various set settings for robust scripts.\nThe script should process one command-line argument, the input file. Assign the automatic placeholder variable for the first argument to a variable with a descriptive name, like fastq_file.\n\nHints\n\nThe automatic placeholder variable for the first argument is $1.\n\n\nIn the sections below, you can print all your output to standard out, i.e. simply use echo with no redirection.\nAlso, just for the purpose of testing the commands while developing them below, it will be convenient to assign one of the FASTQ files to a variable fastq_file.\n\nHave the script report its own name as well as the name of the FASTQ file that is being processed.\n\nHints\n\nRecall that the name of the script is automatically stored in $0.\n\nCompute and report the number of sequences in the FASTQ file.\n\nHints\n\nThe number of sequences can be assumed to be the total number of lines divided by 4 (or alternatively, the number of lines consisting only of a +). Recall that FASTQ files have 4 lines per sequence: a header, the sequence, a + divider, and the quality scores.\nTo make the division, you can use syntax like expr 12 / 4 – and you can use command substitution, $(wc -l ...), to insert the number of lines in the division.\n\nAs mentioned in the Background section, the primer sequences should be present in the FASTQ files. Prior to sequence analyses, these are usually removed with a specialized program like cutadapt, but we can use our grep skills to quickly search for them.\nWe will search for the forward primers only in the forwards reads, and for the reverse primers only in the reverse reads. Therefore, start with an if statement that tests whether the file name contains forward (_R1_) or reverse (_R2_) reads.If it contains forward reads, you should be counting occurrences of the forward primer or its reverse complement. Similarly, if it contains reverse reads you should be counting occurrences of the reverse primer or its reverse complement.\nYou’ll also have to replace the ambiguity codes, like R, with character classes that enumerate the possible alternative bases.\n\nHints\n\nThe test in the if statement should be a grep command that examines whether the filename contains _R1_ (pipe echo output into grep). The grep standard output should be redirected to /dev/null, since we’re only interested in the exit status: if grep finds a match, the commands following then will be executed; if it doesn’t, the commands following else will be executed.\nYou can assume that matches will only be made in the sequences themselves (and not the headers or quality scores), so you can grep the file as is: you don’t need to first select the lines with sequences.\nTo replace ambiguity codes with character classes in the grep regular expression: an R in the primers becomes [AG] in the grep expression, e.g. the partial sequence ATRG would become AT[AG]G in your regular expression.\nYou’ll need both the primer and its reverse complement in a single grep regular expression: separate them with an logical “or” (|) and to enable this, use grep -E for extended regular expressions.\n\nBonus: Print a count table of sequence lengths.\n\nHints\n\nYou’ll have to select only the lines with the actual DNA sequences, and the best way of doing that is using awk like so (see the Solution for an explanation of why this works):\nawk '{ if(NR%4 == 2) }'\nNext, you need to count the number of characters in each line, which is best done in the same awk command using print length($0), which will print the number of characters in the line.\nAfter that, it’s the familiar sort | uniq -c idiom to create a count table.\n\nMake the script executable.\n\nHints\n\nUse the chmod command.\n\nRun the script for a single FASTQ file by calling it from the command line.\n\nExercise 3: Modify the looping script\nNow, let’s modify Buffalo’s script fastq_stat_loop.sh.\nCurrently, the metadata file that contains the list of files to process is hard-coded as samples.txt. Also, the file names have to be extracted from a specific column from the metadata file. This is not a very flexible setup, and is sensitive to minor changes in a file like samples.txt.\nChange the script to let it accept a list of FASTQ file names as an argument.\n\nHints\n\nRecall that the placeholder variable for the first argument that is passed to a script on the command line is $1.\nInside the command substitution ($()) that populates the array, you can simply use cat instead of cut on the file that contains the list of file names, since this file will no longer have multiple columns.\n\nCurrently, the output directory is also hard-coded, as stats – let’s instead add the output directory as a second argument to the script.\nMoreover, add code that creates this output directory if it doesn’t already exist.\n\nHints\n\nYou can write an explicit test to see if the output dir exists first, but simply using mkdir -p will also work: with the -p option, mkdir doesn’t complain when a dir already exists (and can also make multiple levels of directories at once).\n\nChange the line that runs the imaginary program fastq_stat to let it run your fastq_stat.sh script instead. Make sure the path to your script and the path to the output file is correct.\nIn each iteration of the loop, let the script report which FASTQ file will be analyzed.\nNow that the script takes arguments, we need another file or script to create the list of filenames and to submit the script with the appropriate arguments. Specifically, in this file, we need:\nA line that creates a new file just containing the FASTQ file names (akin to column 3 from samples.txt – but with the paths to our actual FASTQ files).\nA line that runs the fastq_stat_loop.sh script. The file that contains the list of FASTQ files should be passed to the script as the first argument, and the output directory as the second argument.\nAs for the actual path to the output dir, you can use whatever (relative!) path makes sense to you.\n\nCreate the file containing the code outlined above. You can save this file either as a .sh script (e.g. fastqc_runner.sh), or put these lines in a Markdown file inside a code block. Either option is reasonable because these lines would likely be run interactively, as opposed to the fastq_stat_loop.sh script which will be run non-interactively. It’s still important to save these interactive commands in a file, so you know what you did and can easily reproduce it.\nMake fastq_stat_loop.sh executable and run it.\nThe loop script should run fastq_stat.sh on all your FASTQ files. Check the output, which should be in one file per FASTQ file in the output dir you designated. You should be seeing that the vast majority of reads contain the primer sequences. Be proud – with a quick script that only runs for a couple of seconds, and no specialized software, you have queried hundreds of thousands of sequences!\n\nExercise 4: Bells and whistles\nIn this exercise, you will touch up your fastqc_stat.sh script to include tests for robustness, and to report what the script is doing.\nFor the tests, check whether they work (…)! For instance, to check the test for the number of arguments, try running the script with no arguments, and also with two arguments, and see if the script produces the error messages you wrote.\nWrite an if statement to check whether the FASTQ file exists / is a regular file and whether it can be read. If not, give an error and exit the script with exit code 1.\n\nHints\n\nGo back to this week’s slides for an example of testing whether a file is a regular file (-f) and whether it can be read (-r).\nTo exit with exit code 1, simply use: exit 1. This should be done after printing any error messages you, or those won’t actually be printed.\n\nTest whether exactly 1 argument was passed to the script on the command line. If not, return an error, succinctly report how to use the script (“usage: …”), and exit with exit code 1.\n\nHints\n\nGo back to this week’s slides for an example of a very similar test.\nThe number of arguments that were passed to a script are automatically available in $#.\nYou can test for equality using <integer> -eq <integer> (e.g. 10 -eq 10 which will evaluate to true) and you can negate a test (\"number of argument is not equal to 1) using a ! before the comparison expression.\n\nAdd date commands at the start and the end of the script, so you’ll be able to tell how long it took the script to complete.\n\nBonus exercises\nExercise 5: Find the longest file2\nWrite a shell script called longest.sh that takes two arguments: the name of a directory and a file extension (like txt). The script should print the name of the file that has the most lines among all files with with that extension in that directory.\nMake sure the script has the shebang and set headers, and make the script executable.\nThen, run your script to learn which FASTQ file has the most lines (and sequences):\n$ ./longest.sh data/fastq fastq\n… should print the name of the .fastq file in data/fastq with the highest number of lines and therefore sequences.\n\nHints\n\nYou can count lines for many files at once using wc -l: simply provide it with a globbing pattern.\n\nExercise 6: Plant-pollinator networks\nThis exercise is slightly modified after 1.10.3 from the CSB book. The Saavedra2013 directory can be found inside the CSB repository at CSB/unix/data/Saavedra2013, and the following code assumes you are in the directory CSB/unix/sandbox. (If you no longer have the repository, download it again using git clone https://github.com/CSB-book/CSB.git.)\nSaavedra and Stouffer (2013) studied several plant–pollinator networks. These can be represented as rectangular matrices where the rows are pollinators, the columns plants, a 0 indicates the absence and 1 the presence of an interaction between the plant and the pollinator.\nThe data of Saavedra and Stouffer (2013) can be found in the directory CSB/unix/data/Saavedra2013.\nWrite a script that takes one of these files as an argument, and determines the number of rows (pollinators) and columns (plants). Note that columns are separated by spaces. Don’t forget to make your script executable and to add the standard header lines. Your script should return:\n$ ./netsize.sh ../data/Saavedra2013/n1.txt\n\n#> Filename: ../data/Saavedra2013/n1.txt\n#> Number of rows: 97\n#> Number of columns: 80\nWrite a script that prints the numbers of rows and columns for each network, taking the directory containing all the files as an argument:\n$ ./netsize_all.sh ../data/Saavedra2013\n\n#> ../data/Saavedra2013/n10.txt     14      20\n#> ../data/Saavedra2013/n11.txt     270     91\n#> ../data/Saavedra2013/n12.txt     7       72\n#> ../data/Saavedra2013/n13.txt     61      17\n#> …\n\nHints\n\nTo find the number of columns, use awk and recall awk’s NF (number of fields => number of columns) keyword.\nTo combine them in a script, use command substitution to assign the result of a command to a variable. (For example: mytxtfiles=$(ls *.txt) stores the list of .txt files in the variable $mytxtfiles.)\nNext, you need to write a for loop.\nYou can now use the script you’ve just written in combination with sort to answer the questions (remember the option -k to choose a column and -r to reverse the sorting order).\nYou can use echo -e to print tabs using \\t: echo -e \"column1 \\t column2\".\n\nExercise 7: Data explorer\nThis is slightly modified after exercise 1.10.4 from the CSB book. The Buzzard2015_data.csv file can be found inside the CSB repository at CSB/unix/data/Buzzard2015_data.csv.\nBuzzard et al. (2016) collected data on the growth of a forest in Costa Rica. In the file Buzzard2015_data.csv you will find a subset of their data, including taxonomic information, abundance, and biomass of trees.\n1. Write a script that, for a given CSV file and column number, prints:\nThe corresponding column name;\nThe number of distinct values in the column;\nThe minimum value;\nThe maximum value.\nDon’t forget to make your script executable and add the standard header lines.\nFor example, running the script with:\n$ ./explore.sh ../data/Buzzard2015_data.csv 7\n…should return:\nColumn name:\nbiomass\nNumber of distinct values:\n285\nMinimum value:\n1.048466198\nMaximum value:\n14897.29471\n\nHints\n\nYou can select a given column from a csv file using the command cut. Then,\nThe column name is going to be in the first line (header); access it with head.\nFor the next few commands, you’ll need to remove the header line – the tail trick to do so is tail -n +2.\nThe number of distinct values can be found by counting the number of lines when you have sorted them and removed duplicates (using a combination of tail, sort and uniq).\nThe minimum and maximum values can be found by combining sort and head (or tail).\nRename the placeholders $1 and $2 for the command-line arguments to named variables for the file name and column number, respectively.\n\nSolutions\nExercise 1\n\n(1.) Create a directory for these exercises.\n\nmkdir /fs/ess/PAS1855/users/$USER/week05/exercises/\n\n\n(3.) Copy the FASTQ files into your own dir.\n\nmkdir -p data/fastq/\ncp /fs/ess/PAS1855/data/week05/fastq/* data/fastq/\n\nExercise 2\n\n(1.) Create a new script with header lines.\n\nThe first two lines of the script:\n#!/bin/bash\nset -u -e -o pipefail\nSave the file as fastq_stat.sh.\n\n\n(2.) Assign the first argument to a named variable.\n\nAdd a line like this to your fastq_stat.sh script:\nfastq_file=$1\n\n\n(3.) Let the script report its name and the name of the FASTQ file.\n\nFor testing the code below, we first assign one of the FASTQ filenames to the variable $fastq_file:\nfastq_file=201-S4-V4-V5_S53_L001_R1_001.fastq\nAdd lines like these to your fastq_stat.sh script:\necho \"$0: A script to compute basic summary stats for a FASTQ file.\"\necho \"FASTQ file to be analyzed: $fastq_file\"\n\n\n(4.) Compute and report the number of sequences in the FASTQ file.\n\nAdd lines like these to your fastq_stat.sh script:\n# We save the output of our commands using command substitution, $().\n# In the wc -l command, use input redirection so the filename is not in the output.\nn_lines=$(wc -l < \"$fastq_file\")\nn_seqs=$(expr \"$n_lines\" / 4)     # Use expr for arithmetics\n\necho \"Number of sequences: $n_seqs\"\nAlternatively, you can use the (( )) syntax for arithmetics – just take care that in this case, there can be no spaces between the mathematical operator and the numbers:\nn_seqs=$((\"$n_lines\"/4))\nTo get the number of sequences, you can also count the number of lines that only have a + symbol:\nn_seqs=$(grep -c \"^+$\" $fastq_file)\nRecall that + is also a regular expression symbol, but only so in the extended regex set. Therefore, without the -E flag to grep, we are matching a literal + when we use one in our expression.\n\n(5.) Search for adapter sequences.\n\nAdd lines like these to your fastq_stat.sh script:\nif echo \"$fastq_file\" | grep \"_R1_\" >/dev/null; then\n\n  echo \"FASTQ file contains forward (R1) reads, checking for primer 1...\"\n\n  n_primerF=$(grep -Ec \"GAGTG[CT]CAGC[AC]GCCGCGGTAA|TTACCGCGGC[GT]GCTG[AG]CACTC\" \"$fastq_file\")\n  echo \"Number of forward primer sequences found: $n_primerF\"\n\nelse\n\n  echo \"FASTQ file contains forward (R2) reads, checking for primer 2...\"\n\n  n_primerR=$(grep -Ec \"ACGGACTAC[ACTG][ACG]GGGT[AT]TCTAAT|ATTAGA[AT]ACCCB[ACTG]GTAGTCCGT\" \"$fastq_file\")\n  echo \"Number of reverse primer sequences found: $n_primerR\"\n\nfi\nTo initiate the if statement:\nWe redirect grep’s output to /dev/null, since we’re only interested in the exit status.\nIf grep finds a match, this evaluates to “true”, and the next code block will be executed. If no match is found, the block after else will be executed.\nInside the if statement:\nWe use the grep’s -E option to search for either of the two primer sequences at once with |.\nWe use character classes like [CT] in place of each ambiguity code.\nWe use grep’s -c option to count the matches.\nOr, to explicitly check the file contains _R2 in its name, rather than assuming this must be the case if it doesn’t contain _R1, you can use elif (short for “else-if”) to add another test:\nif echo \"$fastq_file\" | grep \"_R1_\" >/dev/null; then\n\n  echo \"FASTQ file contains forward (R1) reads, checking for primer 1...\"\n\n  n_primerF=$(grep -Ec \"GAGTG[CT]CAGC[AC]GCCGCGGTAA|TTACCGCGGC[GT]GCTG[AG]CACTC\" \"$fastq_file\")\n  echo \"Number of forward primer sequences found: $n_primerF\"\n\nelif echo \"$fastq_file\" | grep \"_R2_\" >/dev/null; then\n\n  echo \"FASTQ file contains forward (R2) reads, checking for primer 2...\"\n\n  n_primerR=$(grep -Ec \"ACGGACTAC[ACTG][ACG]GGGT[AT]TCTAAT|ATTAGA[AT]ACCCB[ACTG]GTAGTCCGT\" \"$fastq_file\")\n  echo \"Number of reverse primer sequences found: $n_primerR\"\n\nfi\nWhen we test this code by itself, we get:\n#> FASTQ file contains forward (R1) reads, checking for primer 1...\n#> Number of forward primer sequences found: 44687\nThis looks good!\n\n\n(6.) Bonus: Print a count table of sequence lengths.\n\nAdd lines like these to your fastq_stat.sh script:\necho \"Count table of sequence lengths:\"\nawk '{ if(NR%4 == 2) print length($0) }' \"$fastq_file\" | sort | uniq -c\nTo select only actual sequences, and not other lines, from the FASTQ file, we use the following trick. We know that in the FASTQ file, every fourth line, starting from line number 2, contains the actual sequence (i.e.: line 2, line 6, line 10, etc). To select these lines we can use the “modulo” operator to select only line numbers (NR in awk) for which, after dividing the line number by 4, we have 2 left: NR%4 == 2.\nNext we print the number of characters on the entire line using awk’s length function: print length($0).\nFinally, we pass the sequence lengths on to the sort | uniq -c idiom, which will give us a count table.\n\n(7.) Make the script executable.\n\nAssuming it is in the working dir:\n$ chmod u+x fastq_stat.sh \n\n# Or for all scripts at once:\n$ chmod u+x *sh\n\n\n(8.) Run the script for a single FASTQ file by calling it from the command line.\n\n# Assuming you have assigned a FASTQ file to $fastq_file for testing:\n./fastq_stat.sh $fastq_file\n\nExercise 3\n\n(1.) Change the script to let it accept a list of FASTQ file names as an argument.\n\nAdd this line to the script:\nfile_list=\"$1\"\nNow, replace the following line:\n# Old line:\n# sample_files=($(cut -f 3 \"$sample_info\"))\n\n# New line:\nsample_files=($(cat \"$file_list\"))\n\n\n(2.) Add the output directory as a second argument to the script, and create the output dir if necessary.\n\noutput_dir=\"$2\"\n\n# Create the output dir, if necessary:\nmkdir -p \"$output_dir\"\nmkdir -p will not complain if the directory already exists, and it can make multiple levels of directories at once.\n\n(3.) Modify the line in the script that calls fastq_stat to call your script.\n\n# Old line:\n# fastq_stat \"$fastq_file\" > stats/$results_file\n\n# New line:\nscripts/fastq_stat.sh \"$fastq_file\" > \"$output_dir\"/\"$results_file\"\nThe results_file line can remain the same:\nresults_file=\"$(basename $fastq_file .fastq)-stats.txt\"\n\n\n(4.) In each iteration of the loop, let the script report which FASTQ will be analyzed.\n\nAdd the following line inside the loop:\necho \"Running fastq_stat for FASTQ file $fastq_file\"\n\n\n(5.) Create a second file/script to create a list of FASTQ files and to run the loop script.\n\nTo create a list of FASTQ files:\nfile_list=fastq_file_list.txt\n\nls data/*fastq >\"$file_list\"\nTo run the loop script:\noutput_dir=results/fastq_stats\n\n./fastq_stat_loop.sh \"$file_list\" \"$output_dir\"\n\n\n(6.) Make fastq_stat_loop.sh executable and run it.\n\nRun these lines:\n$ chmod u+x ./fastq_stat_loop.sh\n\n$ ./fastq_stat_loop.sh \"$file_list\" \"$output_dir\"\n\nThe final fastq_stat_loop.sh script.\n\n#!/bin/bash\nset -e -u -o pipefail\n\nfile_list=\"$1\"\noutput_dir=\"$2\"\n\n# Create the output dir, if necessary:\nmkdir -p \"$output_dir\"\n\n# Create an array with FASTQ files\nfastq_files=($(cat \"$file_list\"))\n\n# Report:\necho \"Number of fastq files: ${#fastq_files[@]}\"\n\n# Loop through the array:\nfor fastq_file in \"${fastq_files[@]}\"; do\n\n  echo \"Running fastq_stat for FASTQ file $fastq_file\"\n\n  # Strip .fastq from each FASTQ file, and add suffix:\n  results_file=\"$(basename \"$fastq_file\" .fastq)-stats.txt\"\n\n  # Run \"fastq_stat\" on a file:\n  scripts/fastq_stat.sh \"$fastq_file\" >\"$output_dir\"/\"$results_file\"\n\ndone\n\nThe final lines in the runner script / Markdown code block.\n\nfile_list=fastq_file_list.txt\noutput_dir=results/fastq_stats\n\nls data/*fastq >\"$file_list\"\n\n./fastq_stat_loop.sh \"$file_list\" \"$output_dir\"\n\nExercise 4\n\n(1.) Check whether the FASTQ file is a regular file than can be read.\n\nAdd these lines to your script:\n! -f will be true if the file is not a regular/existing file\n! -r will be true if the file is not readable\nWe use || to separate the two conditions with a logical or.\nWith exit 1, we terminate the script with an exit code that indicates failure.\n\nif [ ! -f \"$fastq_file\" ] || [ ! -r \"$fastq_file\" ]; then\n  echo \"Error: can't open file\"\n  echo \"Second argument should be a readable file\"\n  echo \"You provided: $fastq_file\"\n  exit 1\nfi\nTo test your test:\n$ ./fastq_stat.sh blabla \n\n\n(2.) Check whether only one argument was provided.\n\nAdd these lines to your script:\n$# is the number of command-line arguments passed to the script\n-eq will test whether the numbers to the left and right of it are the same, and will return true if they are.\nWe negate this with !: if the number of arguments is NOT 1, then error out.\nexit 1 will exit with exit code 1, which signifies an error / failure.\n\nif [ ! \"$#\" -eq 1 ]; then   # If the number of args does NOT equal 1, then\n  echo \"Error: wrong number of arguments\"\n  echo \"You provided $# arguments, while 1 is required.\"\n  echo \"Usage: fastq_stat.sh <file-name>\"\n  exit 1\nfi\nTo test your test:\n$ ./fastq_stat.sh                      # No args\n$ ./fastq_stat.sh $fastq_file blabla   # Two args\n\n\n(3.) Add date commands.\n\nSimply include two lines with:\ndate\n… in the script, one before file processing, and one after.\n\nThe final fastq_stat.sh script.\n\n#!/bin/bash\nset -u -e -o pipefail\n\necho \"$0: A script to compute basic summary stats for a FASTQ file.\"\ndate\necho\n\n# Test number of args -------------------------------------------------\nif [ ! \"$#\" -eq 1 ]; then\n  echo \"Error: wrong number of arguments\"\n  echo \"You provided $# arguments, while 1 is required.\"\n  echo \"Usage: fastq_stat.sh <file-name>\"\n  exit 1\nfi\n\n# Process command-line args and report ------------------------------------\n\nfastq_file=\"$1\"\n\necho \"FASTQ file to be analyzed: $fastq_file\"\necho\n\nif [ ! -f \"$fastq_file\" ] || [ ! -r \"$fastq_file\" ]; then\n  echo \"Error: can't open file\"\n  echo \"Second argument should be a readable file\"\n  echo \"You provided: $fastq_file\"\n  exit 1\nfi\n\n# Count primer sequences ------------------------------------------------\n\nn_lines=$(wc -l <\"$fastq_file\")\nn_seqs=$(expr \"$n_lines\" / 4)\n\necho \"Number of sequences: $n_seqs\"\n\n# Count primer sequences ------------------------------------------------\n\nif echo \"$fastq_file\" | grep \"_R1_\" >/dev/null; then\n\n  echo \"FASTQ file contains forward (R1) reads, checking for primer 1...\"\n\n  n_primerF=$(grep -Ec \"GAGTG[CT]CAGC[AC]GCCGCGGTAA|TTACCGCGGC[GT]GCTG[AG]CACTC\" \"$fastq_file\")\n  echo \"Number of forward primer sequences found: $n_primerF\"\n\nelif echo \"$fastq_file\" | grep \"_R2_\" >/dev/null; then\n\n  echo \"FASTQ file contains forward (R2) reads, checking for primer 2...\"\n\n  n_primerR=$(grep -Ec \"ACGGACTAC[ACTG][ACG]GGGT[AT]TCTAAT|ATTAGA[AT]ACCCB[ACTG]GTAGTCCGT\" \"$fastq_file\")\n  echo \"Number of reverse primer sequences found: $n_primerR\"\n\nfi\n\n# Bonus: Count table of sequence lengths ---------------------------------\necho \"Count table of sequence lengths:\"\nawk '{ if(NR%4 == 2) print length($0) }' \"$fastq_file\" | sort | uniq -c\n\n# Report ----------------------------------------------------------------\necho\necho \"Done with $0 for $fastq_file.\"\ndate\n\nExercise 5\n\nSolution\n\nThere are several ways to do this, here’s one example:\n#!/bin/bash\nset -u -e -o pipefail\n\ndir=\"$1\"\nextension=\"$2\"\n\nwc -l \"$dir\"/*.\"$extension\" | sort -rn | sed -n '2p'\nYou have to print the second rather than the the first line: the first line will be a total line number count across all files, which wc automatically computes.\nInstead of using sed, you could also use head -n 2 | tail -n 1 to print the second line:\nwc -l \"$dir\"/*.\"$extension\" | sort -rn | head -n 2 | tail -n 1\n(Note also that there are two files with the same number of lines: R1 and R2 files for the same sample always have the same number of reads.)\n\nExercise 6\n\n(1.) Write a script that takes one file and determines the number of rows and columns.\n\n#!/bin/bash\nset -u -e -o pipefail\n\nfile=\"$1\"\n\necho \"Filename:\"\necho \"$file\"\n\n# We can get the number of rows simply by counting the number of lines:\n# To avoid printing the filename we redirect the input like below\n# (Or we could have done: \"cat ../data/Saavedra2013/n10.txt | wc -l\")\necho \"Number of rows:\"\nwc -l < \"$file\"\n\n# To count the number of columns, we use awk - recall that NF is the number\n# of fields (columns), and to print that number only for a single line, we exit:\necho \"Number of columns:\"\nawk '{ print NF; exit }' \"$file\"\n\n# head -n 1 \"$file\" | awk '{ print NF }' # Also works\nWe can save this script as netsize.sh and make it executable using chmod u+x netsize.sh.\n\n\n(2.) Write a script that prints the number of rows and columns for each network.\n\n#!/bin/bash\nset -u -e -o pipefail\n\ndir=\"$1\"\n\n# We can loop over the files using globbing:\nfor file in \"$dir\"/*.txt; do\n\n    # Next, we can save the number of rows and columns in variables:\n    n_row=$(wc -l < \"$file\")\n    n_col=$(awk '{ print NF; exit }' \"$file\")\n    \n    # And print them all on one line:\n    echo -e \"$file \\t $n_row \\t $n_col\"\ndone\nWe can save this script as netsize_all.sh and run it as follows:\n./netsize_all.sh ../data/Saavedra2013\n\n\n(3.) Which network has the largest number of rows and which the largest number of columns?\n\n# Having written the script netsize_all.sh,\n# you can take its output and order it according to rows or columns.\n\n# Sorting by column 2 gives you the file with the largest number of rows:\n$ ./netsize_all.sh | sort -n -r -k 2 | head -n 1\n#> ../data/Saavedra2013/n58.txt 678 90\n\n# Sorting by column 3 gives you the file with the largest number of columns:\n\n$ ./netsize_all.sh | sort -n -r -k 3 | head -n 1\n#>  ../data/Saavedra2013/n56.txt 110 207\n\nExercise 7\n\nSolution\n\n#!/bin/bash\n\nset -u -e -o pipefail\n\nfile=$1    # $1 is the file name\ncolumn=$2  # $2 is the column of interest\n\necho \"Column name:\"\ncut -d ',' -f \"$column\" \"$file\" | head -n 1\n\n# In the next lines, we need to skip the header, which we can do using\n# tail -n +2\necho \"Number of distinct values:\"\ncut -d ',' -f \"$column\" \"$file\" | tail -n +2 | sort | uniq | wc -l\n\necho \"Minimum value:\"\ncut -d ',' -f \"$column\" \"$file\" | tail -n +2 | sort -n | head -n 1\n\necho \"Maximum value:\"\ncut -d ',' -f \"$column\" \"$file\" | tail -n +2 | sort -n | tail -n 1\nIf we save the script as explore.sh, and make it executable, we can run it using:\n./explore.sh ../data/Buzzard2015_data.csv 6\n\n# Column name\n# Abund.n\n# Number of distinct values:\n# 46\n# Minimum value:\n# 1\n# Maximum value:\n# 157\n\n# This works well also for alphabetical order:\n\n./explore.sh ../data/Buzzard2015_data.csv 3\n\n# Column name\n# genus\n# Number of distinct values:\n# 85\n# Minimum value:\n# Acacia\n# Maximum value:\n# Zanthoxylum\n\nThere initially was an error in these primer sequences (one sequence repeated twice), which has been corrected on Friday, Feb 12.↩︎\nThis exercise was slightly modified from Software Carpentry’s Shell Novice tutorial.↩︎\n",
      "last_modified": "2021-04-25T16:27:25-04:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
